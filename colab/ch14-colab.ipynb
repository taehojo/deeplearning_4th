{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ftw5hyfw_nGs"
   },
   "source": [
    "# 14장 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lD8i9xrq_nGw"
   },
   "source": [
    "### 1. 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9Usj9sc8_nGx",
    "outputId": "60c9bedd-f801-4fd1-b388-1442585f9829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'data' already exists and is not an empty directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다.\n",
    "!git clone https://github.com/taehojo/data.git\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m0ZlAXHN_nGy"
   },
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TpeC4rTC_nGz",
    "outputId": "67ecbce3-9463-4f06-f32b-fdc5864a54b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7527 - loss: 0.4578 - val_accuracy: 0.7600 - val_loss: 0.4018\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7596 - loss: 0.3869 - val_accuracy: 0.7592 - val_loss: 0.3562\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7551 - loss: 0.3624 - val_accuracy: 0.7654 - val_loss: 0.3340\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7651 - loss: 0.3396 - val_accuracy: 0.7700 - val_loss: 0.3159\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7806 - loss: 0.3218 - val_accuracy: 0.7754 - val_loss: 0.3062\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7963 - loss: 0.3164 - val_accuracy: 0.8254 - val_loss: 0.2978\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8453 - loss: 0.3032 - val_accuracy: 0.8738 - val_loss: 0.2916\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8853 - loss: 0.3053 - val_accuracy: 0.8915 - val_loss: 0.2853\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9007 - loss: 0.2931 - val_accuracy: 0.9108 - val_loss: 0.2798\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9125 - loss: 0.2938 - val_accuracy: 0.9123 - val_loss: 0.2752\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9159 - loss: 0.2808 - val_accuracy: 0.9215 - val_loss: 0.2706\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9214 - loss: 0.2845 - val_accuracy: 0.9200 - val_loss: 0.2656\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.2659 - val_accuracy: 0.9338 - val_loss: 0.2647\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9308 - loss: 0.2758 - val_accuracy: 0.9238 - val_loss: 0.2554\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9276 - loss: 0.2581 - val_accuracy: 0.9346 - val_loss: 0.2476\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.2601 - val_accuracy: 0.9285 - val_loss: 0.2325\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9327 - loss: 0.2393 - val_accuracy: 0.9346 - val_loss: 0.2173\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9365 - loss: 0.2275 - val_accuracy: 0.9485 - val_loss: 0.2054\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9379 - loss: 0.2117 - val_accuracy: 0.9454 - val_loss: 0.1832\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9423 - loss: 0.1930 - val_accuracy: 0.9446 - val_loss: 0.1691\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9408 - loss: 0.1788 - val_accuracy: 0.9462 - val_loss: 0.1649\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9365 - loss: 0.1726 - val_accuracy: 0.9462 - val_loss: 0.1585\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9385 - loss: 0.1662 - val_accuracy: 0.9462 - val_loss: 0.1565\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9378 - loss: 0.1681 - val_accuracy: 0.9462 - val_loss: 0.1531\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9387 - loss: 0.1653 - val_accuracy: 0.9477 - val_loss: 0.1508\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9406 - loss: 0.1589 - val_accuracy: 0.9500 - val_loss: 0.1533\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9434 - loss: 0.1564 - val_accuracy: 0.9508 - val_loss: 0.1460\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.1534 - val_accuracy: 0.9492 - val_loss: 0.1457\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9413 - loss: 0.1572 - val_accuracy: 0.9515 - val_loss: 0.1417\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9373 - loss: 0.1707 - val_accuracy: 0.9477 - val_loss: 0.1487\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.1594 - val_accuracy: 0.9515 - val_loss: 0.1441\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1475 - val_accuracy: 0.9538 - val_loss: 0.1382\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9418 - loss: 0.1511 - val_accuracy: 0.9562 - val_loss: 0.1429\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9492 - loss: 0.1444 - val_accuracy: 0.9523 - val_loss: 0.1380\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9531 - loss: 0.1365 - val_accuracy: 0.9546 - val_loss: 0.1341\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1462 - val_accuracy: 0.9546 - val_loss: 0.1322\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9478 - loss: 0.1386 - val_accuracy: 0.9562 - val_loss: 0.1314\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9517 - loss: 0.1325 - val_accuracy: 0.9554 - val_loss: 0.1288\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.1320 - val_accuracy: 0.9638 - val_loss: 0.1322\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9549 - loss: 0.1282 - val_accuracy: 0.9585 - val_loss: 0.1260\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.1299 - val_accuracy: 0.9569 - val_loss: 0.1236\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9518 - loss: 0.1283 - val_accuracy: 0.9569 - val_loss: 0.1231\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1212 - val_accuracy: 0.9669 - val_loss: 0.1258\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9551 - loss: 0.1252 - val_accuracy: 0.9654 - val_loss: 0.1230\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9519 - loss: 0.1261 - val_accuracy: 0.9685 - val_loss: 0.1247\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9612 - loss: 0.1202 - val_accuracy: 0.9662 - val_loss: 0.1196\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9604 - loss: 0.1199 - val_accuracy: 0.9554 - val_loss: 0.1220\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9594 - loss: 0.1131 - val_accuracy: 0.9585 - val_loss: 0.1173\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9543 - loss: 0.1242 - val_accuracy: 0.9600 - val_loss: 0.1165\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9557 - loss: 0.1215 - val_accuracy: 0.9638 - val_loss: 0.1155\n"
     ]
    }
   ],
   "source": [
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fqe8H_Cb_nGz",
    "outputId": "2e3f204c-f9b6-4869-b51b-2c12014131a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.1005 \n",
      "Test accuracy: 0.9676923155784607\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nv462wz_nG0"
   },
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbJimFFF_nG1"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AbHJ3gjb_nG1",
    "outputId": "2b240f13-7d5c-4b48-b399-bcb961855b06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다. 앞에서 이미 데이터를 가져왔으므로 주석 처리합니다. 2번 예제만 별도 실행 시 주석을 해제한 후 실행해주세요.\n",
    "# !git clone https://github.com/taehojo/data.git\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8wHnkFW_nG2"
   },
   "source": [
    "### 모델의 저장 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cZ7qFKZe_nG2",
    "outputId": "eb7c1c67-0277-4f5e-c2e6-f162bcd8b3de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.2708.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.6862.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.8638.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.9008.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.8923.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.9046.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.9077.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.9123.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9138.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9131.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9146.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9146.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9154.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9138.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9162.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9138.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9177.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9146.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9146.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9192.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9154.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9185.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9177.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9169.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9185.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9192.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9192.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9200.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9185.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9231.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9185.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9238.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9200.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9215.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9223.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9231.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9223.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9231.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9215.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9254.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9254.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9269.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9285.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9254.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9285.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9277.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9285.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9315.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9269.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9323.keras\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다. \n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bcOwXzrp_nG3",
    "outputId": "afe3f469-4b63-4bf4-e428-37116daec152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.1665 \n",
      "Test accuracy: 0.947692334651947\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX_DdAlb_nG3"
   },
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pDwxitjb_nG3"
   },
   "outputs": [],
   "source": [
    "# 그래프 확인을 위한 긴 학습 (시간이 다소 걸릴수 있습니다)\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zjfuqmQi_nG3",
    "outputId": "f599582f-ed7c-4432-a679-3d1f6ff61a63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947909</td>\n",
       "      <td>0.146468</td>\n",
       "      <td>0.931538</td>\n",
       "      <td>0.176564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947652</td>\n",
       "      <td>0.144558</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.179319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.948422</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.936923</td>\n",
       "      <td>0.171864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.142879</td>\n",
       "      <td>0.933077</td>\n",
       "      <td>0.172869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>0.933846</td>\n",
       "      <td>0.168160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.995124</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.987692</td>\n",
       "      <td>0.073550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.995124</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.073068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.986923</td>\n",
       "      <td>0.075076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.993841</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.986154</td>\n",
       "      <td>0.074530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.995124</td>\n",
       "      <td>0.019136</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.075572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.947909  0.146468      0.931538  0.176564\n",
       "1     0.947652  0.144558      0.930769  0.179319\n",
       "2     0.948422  0.143548      0.936923  0.171864\n",
       "3     0.950475  0.142879      0.933077  0.172869\n",
       "4     0.950475  0.140079      0.933846  0.168160\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.995124  0.019956      0.987692  0.073550\n",
       "1996  0.995124  0.019671      0.988462  0.073068\n",
       "1997  0.994611  0.019932      0.986923  0.075076\n",
       "1998  0.993841  0.020981      0.986154  0.074530\n",
       "1999  0.995124  0.019136      0.988462  0.075572\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다. \n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yij0pMOC_nG4",
    "outputId": "1a0836db-7fdb-470b-9701-defa034f7c85"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "#x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfgIYVvS_nG4"
   },
   "source": [
    "## 4. 학습의 자동 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35U6o4cH_nG4"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NOyIPFzB_nG5",
    "outputId": "76d981d3-20b2-43ff-e769-9fb53ad9360f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다. 앞에서 이미 데이터를 가져왔으므로 주석 처리합니다. 2번 예제만 별도 실행 시 주석을 해제한 후 실행해주세요.\n",
    "# !git clone https://github.com/taehojo/data.git\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVZTtnL4_nG5"
   },
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7EDUE8N5_nG5",
    "outputId": "bcd7aa80-71cf-4946-f600-a6508f128717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6214 - loss: 0.6828 - val_accuracy: 0.8331 - val_loss: 0.3507\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8163 - loss: 0.3459 - val_accuracy: 0.8162 - val_loss: 0.3832\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8099 - loss: 0.3636 - val_accuracy: 0.8623 - val_loss: 0.3382\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8700 - loss: 0.3319 - val_accuracy: 0.8900 - val_loss: 0.3135\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9044 - loss: 0.3004 - val_accuracy: 0.8992 - val_loss: 0.3062\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9052 - loss: 0.3028 - val_accuracy: 0.8977 - val_loss: 0.2990\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9053 - loss: 0.2956 - val_accuracy: 0.8992 - val_loss: 0.2938\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9054 - loss: 0.2849 - val_accuracy: 0.9038 - val_loss: 0.2854\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9066 - loss: 0.2899 - val_accuracy: 0.9038 - val_loss: 0.2771\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9152 - loss: 0.2708 - val_accuracy: 0.9062 - val_loss: 0.2689\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9163 - loss: 0.2715 - val_accuracy: 0.9123 - val_loss: 0.2593\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9281 - loss: 0.2400 - val_accuracy: 0.9162 - val_loss: 0.2490\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9270 - loss: 0.2383 - val_accuracy: 0.9185 - val_loss: 0.2387\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9297 - loss: 0.2270 - val_accuracy: 0.9246 - val_loss: 0.2290\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9332 - loss: 0.2166 - val_accuracy: 0.9277 - val_loss: 0.2208\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9409 - loss: 0.2015 - val_accuracy: 0.9315 - val_loss: 0.2167\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9326 - loss: 0.2199 - val_accuracy: 0.9331 - val_loss: 0.2139\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9348 - loss: 0.2100 - val_accuracy: 0.9300 - val_loss: 0.2131\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9372 - loss: 0.1991 - val_accuracy: 0.9300 - val_loss: 0.2090\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9336 - loss: 0.2014 - val_accuracy: 0.9292 - val_loss: 0.2078\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9315 - loss: 0.2037 - val_accuracy: 0.9292 - val_loss: 0.2063\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9411 - loss: 0.1862 - val_accuracy: 0.9300 - val_loss: 0.2035\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9325 - loss: 0.1975 - val_accuracy: 0.9308 - val_loss: 0.2020\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.2003 - val_accuracy: 0.9300 - val_loss: 0.2015\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9416 - loss: 0.1842 - val_accuracy: 0.9308 - val_loss: 0.1986\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9375 - loss: 0.1968 - val_accuracy: 0.9315 - val_loss: 0.1970\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9437 - loss: 0.1794 - val_accuracy: 0.9323 - val_loss: 0.1951\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9350 - loss: 0.1932 - val_accuracy: 0.9323 - val_loss: 0.1930\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9386 - loss: 0.1856 - val_accuracy: 0.9331 - val_loss: 0.1926\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9415 - loss: 0.1793 - val_accuracy: 0.9346 - val_loss: 0.1888\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9361 - loss: 0.1826 - val_accuracy: 0.9338 - val_loss: 0.1882\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9439 - loss: 0.1703 - val_accuracy: 0.9354 - val_loss: 0.1849\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.1708 - val_accuracy: 0.9362 - val_loss: 0.1841\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9432 - loss: 0.1670 - val_accuracy: 0.9362 - val_loss: 0.1793\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9443 - loss: 0.1688 - val_accuracy: 0.9362 - val_loss: 0.1784\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9468 - loss: 0.1585 - val_accuracy: 0.9369 - val_loss: 0.1731\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9426 - loss: 0.1700 - val_accuracy: 0.9323 - val_loss: 0.1775\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9458 - loss: 0.1602 - val_accuracy: 0.9415 - val_loss: 0.1669\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9437 - loss: 0.1651 - val_accuracy: 0.9392 - val_loss: 0.1673\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9488 - loss: 0.1551 - val_accuracy: 0.9385 - val_loss: 0.1654\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9468 - loss: 0.1506 - val_accuracy: 0.9423 - val_loss: 0.1621\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9471 - loss: 0.1474 - val_accuracy: 0.9446 - val_loss: 0.1600\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9462 - loss: 0.1514 - val_accuracy: 0.9454 - val_loss: 0.1580\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9479 - loss: 0.1457 - val_accuracy: 0.9454 - val_loss: 0.1564\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9481 - loss: 0.1439 - val_accuracy: 0.9454 - val_loss: 0.1542\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9466 - loss: 0.1476 - val_accuracy: 0.9454 - val_loss: 0.1527\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9461 - loss: 0.1475 - val_accuracy: 0.9454 - val_loss: 0.1521\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9474 - loss: 0.1397 - val_accuracy: 0.9469 - val_loss: 0.1484\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1444 - val_accuracy: 0.9438 - val_loss: 0.1508\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9522 - loss: 0.1293 - val_accuracy: 0.9492 - val_loss: 0.1456\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9507 - loss: 0.1322 - val_accuracy: 0.9485 - val_loss: 0.1439\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9530 - loss: 0.1245 - val_accuracy: 0.9477 - val_loss: 0.1437\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9522 - loss: 0.1252 - val_accuracy: 0.9492 - val_loss: 0.1399\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9518 - loss: 0.1289 - val_accuracy: 0.9508 - val_loss: 0.1374\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9556 - loss: 0.1208 - val_accuracy: 0.9515 - val_loss: 0.1369\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9546 - loss: 0.1254 - val_accuracy: 0.9500 - val_loss: 0.1361\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9565 - loss: 0.1171 - val_accuracy: 0.9508 - val_loss: 0.1341\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9569 - loss: 0.1204 - val_accuracy: 0.9554 - val_loss: 0.1328\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1253 - val_accuracy: 0.9508 - val_loss: 0.1346\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9575 - loss: 0.1191 - val_accuracy: 0.9515 - val_loss: 0.1315\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9623 - loss: 0.1131 - val_accuracy: 0.9546 - val_loss: 0.1285\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9608 - loss: 0.1131 - val_accuracy: 0.9554 - val_loss: 0.1285\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9558 - loss: 0.1158 - val_accuracy: 0.9546 - val_loss: 0.1271\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9593 - loss: 0.1161 - val_accuracy: 0.9523 - val_loss: 0.1269\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9550 - loss: 0.1226 - val_accuracy: 0.9562 - val_loss: 0.1256\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9579 - loss: 0.1156 - val_accuracy: 0.9523 - val_loss: 0.1253\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9608 - loss: 0.1113 - val_accuracy: 0.9531 - val_loss: 0.1244\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9577 - loss: 0.1131 - val_accuracy: 0.9569 - val_loss: 0.1224\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9659 - loss: 0.1054 - val_accuracy: 0.9577 - val_loss: 0.1211\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9641 - loss: 0.1063 - val_accuracy: 0.9523 - val_loss: 0.1249\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9635 - loss: 0.1091 - val_accuracy: 0.9546 - val_loss: 0.1207\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9645 - loss: 0.1022 - val_accuracy: 0.9592 - val_loss: 0.1186\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9647 - loss: 0.1015 - val_accuracy: 0.9592 - val_loss: 0.1183\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9637 - loss: 0.0991 - val_accuracy: 0.9600 - val_loss: 0.1177\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1053 - val_accuracy: 0.9538 - val_loss: 0.1191\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9635 - loss: 0.1051 - val_accuracy: 0.9623 - val_loss: 0.1157\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 0.0983 - val_accuracy: 0.9592 - val_loss: 0.1161\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.0974 - val_accuracy: 0.9538 - val_loss: 0.1173\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9633 - loss: 0.1051 - val_accuracy: 0.9523 - val_loss: 0.1204\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9612 - loss: 0.1028 - val_accuracy: 0.9631 - val_loss: 0.1128\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9676 - loss: 0.0999 - val_accuracy: 0.9608 - val_loss: 0.1137\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9635 - loss: 0.1051 - val_accuracy: 0.9538 - val_loss: 0.1173\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9667 - loss: 0.0893 - val_accuracy: 0.9685 - val_loss: 0.1111\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.0955 - val_accuracy: 0.9623 - val_loss: 0.1107\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9698 - loss: 0.0969 - val_accuracy: 0.9562 - val_loss: 0.1149\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9671 - loss: 0.1024 - val_accuracy: 0.9600 - val_loss: 0.1116\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9676 - loss: 0.0916 - val_accuracy: 0.9685 - val_loss: 0.1083\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9763 - loss: 0.0852 - val_accuracy: 0.9654 - val_loss: 0.1073\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9692 - loss: 0.1019 - val_accuracy: 0.9646 - val_loss: 0.1074\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9705 - loss: 0.0942 - val_accuracy: 0.9608 - val_loss: 0.1105\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9686 - loss: 0.0942 - val_accuracy: 0.9646 - val_loss: 0.1063\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9687 - loss: 0.0924 - val_accuracy: 0.9646 - val_loss: 0.1064\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9708 - loss: 0.0865 - val_accuracy: 0.9692 - val_loss: 0.1079\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0951 - val_accuracy: 0.9608 - val_loss: 0.1094\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9732 - loss: 0.0930 - val_accuracy: 0.9654 - val_loss: 0.1056\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9713 - loss: 0.0923 - val_accuracy: 0.9623 - val_loss: 0.1071\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9677 - loss: 0.0853 - val_accuracy: 0.9708 - val_loss: 0.1026\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0879 - val_accuracy: 0.9708 - val_loss: 0.1027\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9772 - loss: 0.0843 - val_accuracy: 0.9708 - val_loss: 0.1020\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.0893 - val_accuracy: 0.9708 - val_loss: 0.1018\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0892 - val_accuracy: 0.9685 - val_loss: 0.1019\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9732 - loss: 0.0906 - val_accuracy: 0.9692 - val_loss: 0.1010\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9737 - loss: 0.0855 - val_accuracy: 0.9577 - val_loss: 0.1111\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9685 - loss: 0.0997 - val_accuracy: 0.9631 - val_loss: 0.1070\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9682 - loss: 0.0929 - val_accuracy: 0.9708 - val_loss: 0.0993\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9732 - loss: 0.0862 - val_accuracy: 0.9715 - val_loss: 0.0986\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.0851 - val_accuracy: 0.9692 - val_loss: 0.1013\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9719 - loss: 0.0981 - val_accuracy: 0.9692 - val_loss: 0.0999\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9746 - loss: 0.0776 - val_accuracy: 0.9723 - val_loss: 0.0969\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9785 - loss: 0.0821 - val_accuracy: 0.9731 - val_loss: 0.0979\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.0799 - val_accuracy: 0.9738 - val_loss: 0.0971\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9734 - loss: 0.0873 - val_accuracy: 0.9723 - val_loss: 0.0959\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.0822 - val_accuracy: 0.9738 - val_loss: 0.0954\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9744 - loss: 0.0847 - val_accuracy: 0.9646 - val_loss: 0.1034\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.0879 - val_accuracy: 0.9731 - val_loss: 0.0953\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9742 - loss: 0.0831 - val_accuracy: 0.9731 - val_loss: 0.0950\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9749 - loss: 0.0854 - val_accuracy: 0.9615 - val_loss: 0.1079\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9715 - loss: 0.0810 - val_accuracy: 0.9731 - val_loss: 0.0942\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0811 - val_accuracy: 0.9738 - val_loss: 0.0949\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9765 - loss: 0.0712 - val_accuracy: 0.9731 - val_loss: 0.0936\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0782 - val_accuracy: 0.9715 - val_loss: 0.0966\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9741 - loss: 0.0805 - val_accuracy: 0.9708 - val_loss: 0.0983\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0724 - val_accuracy: 0.9738 - val_loss: 0.0920\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9779 - loss: 0.0746 - val_accuracy: 0.9754 - val_loss: 0.0919\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9751 - loss: 0.0760 - val_accuracy: 0.9738 - val_loss: 0.0910\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9757 - loss: 0.0727 - val_accuracy: 0.9738 - val_loss: 0.0903\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0751 - val_accuracy: 0.9762 - val_loss: 0.0921\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.0813 - val_accuracy: 0.9754 - val_loss: 0.0920\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0718 - val_accuracy: 0.9762 - val_loss: 0.0917\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0780 - val_accuracy: 0.9708 - val_loss: 0.0962\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9776 - loss: 0.0749 - val_accuracy: 0.9746 - val_loss: 0.0891\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9788 - loss: 0.0777 - val_accuracy: 0.9762 - val_loss: 0.0896\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9771 - loss: 0.0812 - val_accuracy: 0.9746 - val_loss: 0.0929\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9801 - loss: 0.0729 - val_accuracy: 0.9762 - val_loss: 0.0877\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9777 - loss: 0.0707 - val_accuracy: 0.9762 - val_loss: 0.0875\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.0767 - val_accuracy: 0.9769 - val_loss: 0.0869\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9785 - loss: 0.0712 - val_accuracy: 0.9769 - val_loss: 0.0864\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0773 - val_accuracy: 0.9762 - val_loss: 0.0910\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9786 - loss: 0.0697 - val_accuracy: 0.9769 - val_loss: 0.0859\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9780 - loss: 0.0695 - val_accuracy: 0.9777 - val_loss: 0.0856\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9789 - loss: 0.0711 - val_accuracy: 0.9769 - val_loss: 0.0855\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.0682 - val_accuracy: 0.9785 - val_loss: 0.0848\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9793 - loss: 0.0713 - val_accuracy: 0.9777 - val_loss: 0.0844\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9769 - loss: 0.0776 - val_accuracy: 0.9777 - val_loss: 0.0848\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9793 - loss: 0.0686 - val_accuracy: 0.9777 - val_loss: 0.0833\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0634 - val_accuracy: 0.9777 - val_loss: 0.0838\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0679 - val_accuracy: 0.9792 - val_loss: 0.0841\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9805 - loss: 0.0659 - val_accuracy: 0.9777 - val_loss: 0.0823\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0732 - val_accuracy: 0.9762 - val_loss: 0.0837\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9801 - loss: 0.0690 - val_accuracy: 0.9746 - val_loss: 0.0860\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0677 - val_accuracy: 0.9792 - val_loss: 0.0820\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0684 - val_accuracy: 0.9808 - val_loss: 0.0810\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9799 - loss: 0.0676 - val_accuracy: 0.9785 - val_loss: 0.0807\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0666 - val_accuracy: 0.9785 - val_loss: 0.0807\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9818 - loss: 0.0644 - val_accuracy: 0.9785 - val_loss: 0.0816\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9784 - loss: 0.0687 - val_accuracy: 0.9754 - val_loss: 0.0842\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9810 - loss: 0.0664 - val_accuracy: 0.9792 - val_loss: 0.0806\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.0638 - val_accuracy: 0.9792 - val_loss: 0.0796\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0706 - val_accuracy: 0.9777 - val_loss: 0.0809\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.0686 - val_accuracy: 0.9723 - val_loss: 0.0908\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.0672 - val_accuracy: 0.9769 - val_loss: 0.0819\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.0620 - val_accuracy: 0.9754 - val_loss: 0.0892\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0707 - val_accuracy: 0.9746 - val_loss: 0.0835\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.0699 - val_accuracy: 0.9754 - val_loss: 0.0827\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0577 - val_accuracy: 0.9792 - val_loss: 0.0781\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0632 - val_accuracy: 0.9785 - val_loss: 0.0787\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0629 - val_accuracy: 0.9785 - val_loss: 0.0783\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9806 - loss: 0.0682 - val_accuracy: 0.9800 - val_loss: 0.0772\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9801 - loss: 0.0638 - val_accuracy: 0.9792 - val_loss: 0.0772\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0714 - val_accuracy: 0.9738 - val_loss: 0.0877\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9787 - loss: 0.0608 - val_accuracy: 0.9792 - val_loss: 0.0771\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.0599 - val_accuracy: 0.9777 - val_loss: 0.0785\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0603 - val_accuracy: 0.9785 - val_loss: 0.0756\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0588 - val_accuracy: 0.9785 - val_loss: 0.0774\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0605 - val_accuracy: 0.9746 - val_loss: 0.0810\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9793 - loss: 0.0626 - val_accuracy: 0.9792 - val_loss: 0.0755\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0582 - val_accuracy: 0.9754 - val_loss: 0.0802\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.0611 - val_accuracy: 0.9800 - val_loss: 0.0751\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0555 - val_accuracy: 0.9777 - val_loss: 0.0745\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0605 - val_accuracy: 0.9785 - val_loss: 0.0761\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0568 - val_accuracy: 0.9792 - val_loss: 0.0760\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0558 - val_accuracy: 0.9785 - val_loss: 0.0773\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0632 - val_accuracy: 0.9792 - val_loss: 0.0748\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9788 - loss: 0.0704 - val_accuracy: 0.9792 - val_loss: 0.0751\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.0589 - val_accuracy: 0.9785 - val_loss: 0.0760\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0593 - val_accuracy: 0.9800 - val_loss: 0.0727\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0568 - val_accuracy: 0.9777 - val_loss: 0.0752\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0603 - val_accuracy: 0.9777 - val_loss: 0.0731\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0625 - val_accuracy: 0.9792 - val_loss: 0.0754\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0616 - val_accuracy: 0.9800 - val_loss: 0.0724\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0585 - val_accuracy: 0.9792 - val_loss: 0.0733\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.0600 - val_accuracy: 0.9777 - val_loss: 0.0777\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0574 - val_accuracy: 0.9785 - val_loss: 0.0714\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.0500 - val_accuracy: 0.9792 - val_loss: 0.0716\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0584 - val_accuracy: 0.9792 - val_loss: 0.0721\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0564 - val_accuracy: 0.9746 - val_loss: 0.0706\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0575 - val_accuracy: 0.9785 - val_loss: 0.0702\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9824 - loss: 0.0587 - val_accuracy: 0.9777 - val_loss: 0.0705\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0543 - val_accuracy: 0.9792 - val_loss: 0.0710\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0550 - val_accuracy: 0.9785 - val_loss: 0.0702\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0644 - val_accuracy: 0.9762 - val_loss: 0.0701\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0527 - val_accuracy: 0.9769 - val_loss: 0.0692\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0502 - val_accuracy: 0.9785 - val_loss: 0.0698\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0531 - val_accuracy: 0.9800 - val_loss: 0.0701\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9844 - loss: 0.0595 - val_accuracy: 0.9792 - val_loss: 0.0695\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0590 - val_accuracy: 0.9769 - val_loss: 0.0773\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0535 - val_accuracy: 0.9800 - val_loss: 0.0707\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0528 - val_accuracy: 0.9777 - val_loss: 0.0683\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0545 - val_accuracy: 0.9800 - val_loss: 0.0712\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0545 - val_accuracy: 0.9800 - val_loss: 0.0681\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0531 - val_accuracy: 0.9800 - val_loss: 0.0687\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0493 - val_accuracy: 0.9762 - val_loss: 0.0678\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0475 - val_accuracy: 0.9762 - val_loss: 0.0680\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0555 - val_accuracy: 0.9800 - val_loss: 0.0692\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0493 - val_accuracy: 0.9792 - val_loss: 0.0717\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0580 - val_accuracy: 0.9754 - val_loss: 0.0806\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0608 - val_accuracy: 0.9792 - val_loss: 0.0713\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0563 - val_accuracy: 0.9785 - val_loss: 0.0683\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0532 - val_accuracy: 0.9800 - val_loss: 0.0684\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.0536 - val_accuracy: 0.9762 - val_loss: 0.0673\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0524 - val_accuracy: 0.9792 - val_loss: 0.0694\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0542 - val_accuracy: 0.9785 - val_loss: 0.0725\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0503 - val_accuracy: 0.9800 - val_loss: 0.0697\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0586 - val_accuracy: 0.9792 - val_loss: 0.0710\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.0548 - val_accuracy: 0.9754 - val_loss: 0.0672\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.0494 - val_accuracy: 0.9769 - val_loss: 0.0664\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0536 - val_accuracy: 0.9746 - val_loss: 0.0664\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.0601 - val_accuracy: 0.9785 - val_loss: 0.0683\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0589 - val_accuracy: 0.9769 - val_loss: 0.0658\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0525 - val_accuracy: 0.9762 - val_loss: 0.0656\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0513 - val_accuracy: 0.9792 - val_loss: 0.0665\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0433 - val_accuracy: 0.9785 - val_loss: 0.0699\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0519 - val_accuracy: 0.9769 - val_loss: 0.0664\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0523 - val_accuracy: 0.9800 - val_loss: 0.0690\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.0549 - val_accuracy: 0.9785 - val_loss: 0.0678\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0525 - val_accuracy: 0.9800 - val_loss: 0.0657\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9855 - loss: 0.0504 - val_accuracy: 0.9800 - val_loss: 0.0652\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0498 - val_accuracy: 0.9777 - val_loss: 0.0655\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0554 - val_accuracy: 0.9769 - val_loss: 0.0664\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.0470 - val_accuracy: 0.9777 - val_loss: 0.0659\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0493 - val_accuracy: 0.9800 - val_loss: 0.0654\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0470 - val_accuracy: 0.9800 - val_loss: 0.0690\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0475 - val_accuracy: 0.9777 - val_loss: 0.0667\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0506 - val_accuracy: 0.9785 - val_loss: 0.0669\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0519 - val_accuracy: 0.9777 - val_loss: 0.0659\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0476 - val_accuracy: 0.9792 - val_loss: 0.0659\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0505 - val_accuracy: 0.9792 - val_loss: 0.0678\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9854 - loss: 0.0527 - val_accuracy: 0.9800 - val_loss: 0.0647\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0463 - val_accuracy: 0.9769 - val_loss: 0.0655\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0481 - val_accuracy: 0.9800 - val_loss: 0.0641\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0500 - val_accuracy: 0.9792 - val_loss: 0.0641\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0472 - val_accuracy: 0.9777 - val_loss: 0.0650\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.0518 - val_accuracy: 0.9769 - val_loss: 0.0638\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0487 - val_accuracy: 0.9800 - val_loss: 0.0685\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0545 - val_accuracy: 0.9769 - val_loss: 0.0646\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9834 - loss: 0.0555 - val_accuracy: 0.9792 - val_loss: 0.0659\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0482 - val_accuracy: 0.9800 - val_loss: 0.0643\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0474 - val_accuracy: 0.9762 - val_loss: 0.0637\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0433 - val_accuracy: 0.9746 - val_loss: 0.0638\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0463 - val_accuracy: 0.9808 - val_loss: 0.0669\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0550 - val_accuracy: 0.9769 - val_loss: 0.0637\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0468 - val_accuracy: 0.9800 - val_loss: 0.0694\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0507 - val_accuracy: 0.9769 - val_loss: 0.0627\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0505 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0459 - val_accuracy: 0.9800 - val_loss: 0.0628\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0562 - val_accuracy: 0.9792 - val_loss: 0.0693\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0490 - val_accuracy: 0.9785 - val_loss: 0.0648\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0477 - val_accuracy: 0.9785 - val_loss: 0.0625\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0473 - val_accuracy: 0.9762 - val_loss: 0.0768\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0605 - val_accuracy: 0.9769 - val_loss: 0.0646\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0565 - val_accuracy: 0.9792 - val_loss: 0.0670\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0488 - val_accuracy: 0.9800 - val_loss: 0.0623\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0388 - val_accuracy: 0.9800 - val_loss: 0.0635\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0546 - val_accuracy: 0.9800 - val_loss: 0.0622\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0496 - val_accuracy: 0.9762 - val_loss: 0.0629\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0459 - val_accuracy: 0.9769 - val_loss: 0.0647\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.0413 - val_accuracy: 0.9800 - val_loss: 0.0624\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0545 - val_accuracy: 0.9815 - val_loss: 0.0656\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0524 - val_accuracy: 0.9754 - val_loss: 0.0626\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9868 - loss: 0.0454 - val_accuracy: 0.9769 - val_loss: 0.0631\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0422 - val_accuracy: 0.9800 - val_loss: 0.0659\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0532 - val_accuracy: 0.9785 - val_loss: 0.0618\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0491 - val_accuracy: 0.9800 - val_loss: 0.0624\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0446 - val_accuracy: 0.9785 - val_loss: 0.0617\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0429 - val_accuracy: 0.9792 - val_loss: 0.0613\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0478 - val_accuracy: 0.9785 - val_loss: 0.0614\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.0434 - val_accuracy: 0.9792 - val_loss: 0.0632\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0496 - val_accuracy: 0.9785 - val_loss: 0.0636\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0428 - val_accuracy: 0.9800 - val_loss: 0.0625\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0507 - val_accuracy: 0.9769 - val_loss: 0.0618\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9874 - loss: 0.0456 - val_accuracy: 0.9785 - val_loss: 0.0612\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0576 - val_accuracy: 0.9762 - val_loss: 0.0616\n",
      "Epoch 293/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0418 - val_accuracy: 0.9800 - val_loss: 0.0628\n",
      "Epoch 294/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0517 - val_accuracy: 0.9800 - val_loss: 0.0634\n",
      "Epoch 295/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0479 - val_accuracy: 0.9800 - val_loss: 0.0621\n",
      "Epoch 296/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0513 - val_accuracy: 0.9762 - val_loss: 0.0615\n",
      "Epoch 297/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0411 - val_accuracy: 0.9792 - val_loss: 0.0603\n",
      "Epoch 298/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9863 - loss: 0.0481 - val_accuracy: 0.9800 - val_loss: 0.0616\n",
      "Epoch 299/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0555 - val_accuracy: 0.9792 - val_loss: 0.0605\n",
      "Epoch 300/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0482 - val_accuracy: 0.9792 - val_loss: 0.0613\n",
      "Epoch 301/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0461 - val_accuracy: 0.9785 - val_loss: 0.0606\n",
      "Epoch 302/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0440 - val_accuracy: 0.9808 - val_loss: 0.0613\n",
      "Epoch 303/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0501 - val_accuracy: 0.9808 - val_loss: 0.0607\n",
      "Epoch 304/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0414 - val_accuracy: 0.9792 - val_loss: 0.0607\n",
      "Epoch 305/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0469 - val_accuracy: 0.9785 - val_loss: 0.0618\n",
      "Epoch 306/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0510 - val_accuracy: 0.9808 - val_loss: 0.0607\n",
      "Epoch 307/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0449 - val_accuracy: 0.9815 - val_loss: 0.0651\n",
      "Epoch 308/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0463 - val_accuracy: 0.9769 - val_loss: 0.0612\n",
      "Epoch 309/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0413 - val_accuracy: 0.9792 - val_loss: 0.0612\n",
      "Epoch 310/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0418 - val_accuracy: 0.9777 - val_loss: 0.0595\n",
      "Epoch 311/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0483 - val_accuracy: 0.9777 - val_loss: 0.0594\n",
      "Epoch 312/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0464 - val_accuracy: 0.9777 - val_loss: 0.0596\n",
      "Epoch 313/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0412 - val_accuracy: 0.9792 - val_loss: 0.0595\n",
      "Epoch 314/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0478 - val_accuracy: 0.9785 - val_loss: 0.0624\n",
      "Epoch 315/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0432 - val_accuracy: 0.9815 - val_loss: 0.0587\n",
      "Epoch 316/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0419 - val_accuracy: 0.9808 - val_loss: 0.0589\n",
      "Epoch 317/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0395 - val_accuracy: 0.9792 - val_loss: 0.0585\n",
      "Epoch 318/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0491 - val_accuracy: 0.9800 - val_loss: 0.0587\n",
      "Epoch 319/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0450 - val_accuracy: 0.9792 - val_loss: 0.0578\n",
      "Epoch 320/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0406 - val_accuracy: 0.9792 - val_loss: 0.0585\n",
      "Epoch 321/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0500 - val_accuracy: 0.9792 - val_loss: 0.0583\n",
      "Epoch 322/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0511 - val_accuracy: 0.9785 - val_loss: 0.0652\n",
      "Epoch 323/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0407 - val_accuracy: 0.9800 - val_loss: 0.0601\n",
      "Epoch 324/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0466 - val_accuracy: 0.9800 - val_loss: 0.0576\n",
      "Epoch 325/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0484 - val_accuracy: 0.9792 - val_loss: 0.0669\n",
      "Epoch 326/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0476 - val_accuracy: 0.9800 - val_loss: 0.0579\n",
      "Epoch 327/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0466 - val_accuracy: 0.9808 - val_loss: 0.0587\n",
      "Epoch 328/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0495 - val_accuracy: 0.9800 - val_loss: 0.0579\n",
      "Epoch 329/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0403 - val_accuracy: 0.9800 - val_loss: 0.0605\n",
      "Epoch 330/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0420 - val_accuracy: 0.9808 - val_loss: 0.0582\n",
      "Epoch 331/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0455 - val_accuracy: 0.9808 - val_loss: 0.0581\n",
      "Epoch 332/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0434 - val_accuracy: 0.9808 - val_loss: 0.0578\n",
      "Epoch 333/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9872 - loss: 0.0448 - val_accuracy: 0.9792 - val_loss: 0.0576\n",
      "Epoch 334/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0454 - val_accuracy: 0.9808 - val_loss: 0.0578\n",
      "Epoch 335/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0405 - val_accuracy: 0.9808 - val_loss: 0.0580\n",
      "Epoch 336/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9856 - loss: 0.0511 - val_accuracy: 0.9808 - val_loss: 0.0572\n",
      "Epoch 337/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0418 - val_accuracy: 0.9808 - val_loss: 0.0577\n",
      "Epoch 338/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0399 - val_accuracy: 0.9792 - val_loss: 0.0594\n",
      "Epoch 339/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0463 - val_accuracy: 0.9800 - val_loss: 0.0581\n",
      "Epoch 340/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0442 - val_accuracy: 0.9800 - val_loss: 0.0564\n",
      "Epoch 341/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9895 - loss: 0.0405 - val_accuracy: 0.9815 - val_loss: 0.0572\n",
      "Epoch 342/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0429 - val_accuracy: 0.9808 - val_loss: 0.0568\n",
      "Epoch 343/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0452 - val_accuracy: 0.9777 - val_loss: 0.0605\n",
      "Epoch 344/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0450 - val_accuracy: 0.9785 - val_loss: 0.0644\n",
      "Epoch 345/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0477 - val_accuracy: 0.9800 - val_loss: 0.0562\n",
      "Epoch 346/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0432 - val_accuracy: 0.9785 - val_loss: 0.0584\n",
      "Epoch 347/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0460 - val_accuracy: 0.9800 - val_loss: 0.0568\n",
      "Epoch 348/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0424 - val_accuracy: 0.9808 - val_loss: 0.0558\n",
      "Epoch 349/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0440 - val_accuracy: 0.9800 - val_loss: 0.0560\n",
      "Epoch 350/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0368 - val_accuracy: 0.9769 - val_loss: 0.0702\n",
      "Epoch 351/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.0470 - val_accuracy: 0.9800 - val_loss: 0.0603\n",
      "Epoch 352/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.0495 - val_accuracy: 0.9792 - val_loss: 0.0712\n",
      "Epoch 353/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0495 - val_accuracy: 0.9815 - val_loss: 0.0567\n",
      "Epoch 354/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0408 - val_accuracy: 0.9800 - val_loss: 0.0574\n",
      "Epoch 355/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0443 - val_accuracy: 0.9823 - val_loss: 0.0561\n",
      "Epoch 356/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0445 - val_accuracy: 0.9800 - val_loss: 0.0557\n",
      "Epoch 357/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0397 - val_accuracy: 0.9808 - val_loss: 0.0585\n",
      "Epoch 358/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0396 - val_accuracy: 0.9815 - val_loss: 0.0568\n",
      "Epoch 359/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0432 - val_accuracy: 0.9823 - val_loss: 0.0565\n",
      "Epoch 360/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0452 - val_accuracy: 0.9792 - val_loss: 0.0581\n",
      "Epoch 361/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0387 - val_accuracy: 0.9800 - val_loss: 0.0565\n",
      "Epoch 362/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0470 - val_accuracy: 0.9792 - val_loss: 0.0666\n",
      "Epoch 363/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0463 - val_accuracy: 0.9792 - val_loss: 0.0565\n",
      "Epoch 364/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0408 - val_accuracy: 0.9808 - val_loss: 0.0590\n",
      "Epoch 365/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0382 - val_accuracy: 0.9808 - val_loss: 0.0580\n",
      "Epoch 366/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0447 - val_accuracy: 0.9792 - val_loss: 0.0570\n",
      "Epoch 367/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0505 - val_accuracy: 0.9792 - val_loss: 0.0707\n",
      "Epoch 368/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0425 - val_accuracy: 0.9823 - val_loss: 0.0555\n",
      "Epoch 369/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0444 - val_accuracy: 0.9800 - val_loss: 0.0576\n",
      "Epoch 370/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0442 - val_accuracy: 0.9815 - val_loss: 0.0574\n",
      "Epoch 371/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0480 - val_accuracy: 0.9808 - val_loss: 0.0559\n",
      "Epoch 372/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0451 - val_accuracy: 0.9815 - val_loss: 0.0567\n",
      "Epoch 373/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0390 - val_accuracy: 0.9808 - val_loss: 0.0558\n",
      "Epoch 374/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9891 - loss: 0.0446 - val_accuracy: 0.9792 - val_loss: 0.0619\n",
      "Epoch 375/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0368 - val_accuracy: 0.9823 - val_loss: 0.0556\n",
      "Epoch 376/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0381 - val_accuracy: 0.9800 - val_loss: 0.0558\n",
      "Epoch 377/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9869 - loss: 0.0505 - val_accuracy: 0.9785 - val_loss: 0.0673\n",
      "Epoch 378/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9880 - loss: 0.0430 - val_accuracy: 0.9815 - val_loss: 0.0547\n",
      "Epoch 379/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0433 - val_accuracy: 0.9823 - val_loss: 0.0547\n",
      "Epoch 380/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0416 - val_accuracy: 0.9777 - val_loss: 0.0607\n",
      "Epoch 381/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0493 - val_accuracy: 0.9792 - val_loss: 0.0694\n",
      "Epoch 382/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0507 - val_accuracy: 0.9823 - val_loss: 0.0551\n",
      "Epoch 383/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0429 - val_accuracy: 0.9808 - val_loss: 0.0557\n",
      "Epoch 384/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0378 - val_accuracy: 0.9815 - val_loss: 0.0547\n",
      "Epoch 385/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0487 - val_accuracy: 0.9823 - val_loss: 0.0548\n",
      "Epoch 386/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9871 - loss: 0.0424 - val_accuracy: 0.9831 - val_loss: 0.0541\n",
      "Epoch 387/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0420 - val_accuracy: 0.9838 - val_loss: 0.0551\n",
      "Epoch 388/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0408 - val_accuracy: 0.9792 - val_loss: 0.0580\n",
      "Epoch 389/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0444 - val_accuracy: 0.9777 - val_loss: 0.0618\n",
      "Epoch 390/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0347 - val_accuracy: 0.9815 - val_loss: 0.0587\n",
      "Epoch 391/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0473 - val_accuracy: 0.9808 - val_loss: 0.0552\n",
      "Epoch 392/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0380 - val_accuracy: 0.9823 - val_loss: 0.0552\n",
      "Epoch 393/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0444 - val_accuracy: 0.9800 - val_loss: 0.0568\n",
      "Epoch 394/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 0.0382 - val_accuracy: 0.9800 - val_loss: 0.0566\n",
      "Epoch 395/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0487 - val_accuracy: 0.9808 - val_loss: 0.0563\n",
      "Epoch 396/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9860 - loss: 0.0496 - val_accuracy: 0.9831 - val_loss: 0.0538\n",
      "Epoch 397/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0422 - val_accuracy: 0.9808 - val_loss: 0.0538\n",
      "Epoch 398/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0413 - val_accuracy: 0.9808 - val_loss: 0.0548\n",
      "Epoch 399/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0393 - val_accuracy: 0.9808 - val_loss: 0.0542\n",
      "Epoch 400/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0422 - val_accuracy: 0.9838 - val_loss: 0.0549\n",
      "Epoch 401/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9891 - loss: 0.0411 - val_accuracy: 0.9831 - val_loss: 0.0536\n",
      "Epoch 402/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9871 - loss: 0.0474 - val_accuracy: 0.9808 - val_loss: 0.0545\n",
      "Epoch 403/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0385 - val_accuracy: 0.9823 - val_loss: 0.0535\n",
      "Epoch 404/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0398 - val_accuracy: 0.9823 - val_loss: 0.0548\n",
      "Epoch 405/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0464 - val_accuracy: 0.9815 - val_loss: 0.0567\n",
      "Epoch 406/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9911 - loss: 0.0394 - val_accuracy: 0.9831 - val_loss: 0.0538\n",
      "Epoch 407/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0405 - val_accuracy: 0.9831 - val_loss: 0.0543\n",
      "Epoch 408/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0311 - val_accuracy: 0.9831 - val_loss: 0.0536\n",
      "Epoch 409/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0457 - val_accuracy: 0.9823 - val_loss: 0.0566\n",
      "Epoch 410/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9873 - loss: 0.0446 - val_accuracy: 0.9792 - val_loss: 0.0605\n",
      "Epoch 411/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0499 - val_accuracy: 0.9831 - val_loss: 0.0537\n",
      "Epoch 412/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0499 - val_accuracy: 0.9815 - val_loss: 0.0542\n",
      "Epoch 413/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0371 - val_accuracy: 0.9831 - val_loss: 0.0534\n",
      "Epoch 414/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0340 - val_accuracy: 0.9815 - val_loss: 0.0535\n",
      "Epoch 415/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0392 - val_accuracy: 0.9808 - val_loss: 0.0535\n",
      "Epoch 416/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0356 - val_accuracy: 0.9823 - val_loss: 0.0543\n",
      "Epoch 417/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.9831 - val_loss: 0.0534\n",
      "Epoch 418/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9881 - loss: 0.0376 - val_accuracy: 0.9823 - val_loss: 0.0534\n",
      "Epoch 419/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9871 - loss: 0.0387 - val_accuracy: 0.9815 - val_loss: 0.0530\n",
      "Epoch 420/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.0375 - val_accuracy: 0.9808 - val_loss: 0.0529\n",
      "Epoch 421/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0337 - val_accuracy: 0.9808 - val_loss: 0.0534\n",
      "Epoch 422/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0365 - val_accuracy: 0.9792 - val_loss: 0.0545\n",
      "Epoch 423/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0437 - val_accuracy: 0.9815 - val_loss: 0.0546\n",
      "Epoch 424/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0362 - val_accuracy: 0.9808 - val_loss: 0.0562\n",
      "Epoch 425/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0417 - val_accuracy: 0.9815 - val_loss: 0.0529\n",
      "Epoch 426/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0408 - val_accuracy: 0.9815 - val_loss: 0.0531\n",
      "Epoch 427/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0385 - val_accuracy: 0.9815 - val_loss: 0.0576\n",
      "Epoch 428/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0435 - val_accuracy: 0.9838 - val_loss: 0.0542\n",
      "Epoch 429/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0401 - val_accuracy: 0.9792 - val_loss: 0.0570\n",
      "Epoch 430/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.0408 - val_accuracy: 0.9831 - val_loss: 0.0533\n",
      "Epoch 431/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0399 - val_accuracy: 0.9815 - val_loss: 0.0546\n",
      "Epoch 432/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0477 - val_accuracy: 0.9792 - val_loss: 0.0562\n",
      "Epoch 433/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0362 - val_accuracy: 0.9823 - val_loss: 0.0535\n",
      "Epoch 434/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0495 - val_accuracy: 0.9800 - val_loss: 0.0544\n",
      "Epoch 435/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0375 - val_accuracy: 0.9846 - val_loss: 0.0556\n",
      "Epoch 436/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9898 - loss: 0.0410 - val_accuracy: 0.9838 - val_loss: 0.0522\n",
      "Epoch 437/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0348 - val_accuracy: 0.9838 - val_loss: 0.0524\n",
      "Epoch 438/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0345 - val_accuracy: 0.9831 - val_loss: 0.0533\n",
      "Epoch 439/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0352 - val_accuracy: 0.9815 - val_loss: 0.0523\n",
      "Epoch 440/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0373 - val_accuracy: 0.9815 - val_loss: 0.0526\n",
      "Epoch 441/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.0344 - val_accuracy: 0.9838 - val_loss: 0.0527\n",
      "Epoch 442/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0370 - val_accuracy: 0.9831 - val_loss: 0.0534\n",
      "Epoch 443/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0375 - val_accuracy: 0.9838 - val_loss: 0.0532\n",
      "Epoch 444/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0409 - val_accuracy: 0.9800 - val_loss: 0.0535\n",
      "Epoch 445/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0415 - val_accuracy: 0.9823 - val_loss: 0.0535\n",
      "Epoch 446/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0370 - val_accuracy: 0.9846 - val_loss: 0.0525\n",
      "Epoch 447/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0363 - val_accuracy: 0.9815 - val_loss: 0.0527\n",
      "Epoch 448/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0419 - val_accuracy: 0.9831 - val_loss: 0.0532\n",
      "Epoch 449/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0438 - val_accuracy: 0.9838 - val_loss: 0.0535\n",
      "Epoch 450/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0397 - val_accuracy: 0.9838 - val_loss: 0.0524\n",
      "Epoch 451/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0378 - val_accuracy: 0.9823 - val_loss: 0.0535\n",
      "Epoch 452/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0385 - val_accuracy: 0.9846 - val_loss: 0.0528\n",
      "Epoch 453/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0379 - val_accuracy: 0.9792 - val_loss: 0.0552\n",
      "Epoch 454/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0323 - val_accuracy: 0.9815 - val_loss: 0.0530\n",
      "Epoch 455/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9890 - loss: 0.0397 - val_accuracy: 0.9815 - val_loss: 0.0519\n",
      "Epoch 456/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0408 - val_accuracy: 0.9831 - val_loss: 0.0537\n",
      "Epoch 457/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0465 - val_accuracy: 0.9808 - val_loss: 0.0547\n",
      "Epoch 458/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0475 - val_accuracy: 0.9823 - val_loss: 0.0520\n",
      "Epoch 459/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.0384 - val_accuracy: 0.9800 - val_loss: 0.0585\n",
      "Epoch 460/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9872 - loss: 0.0428 - val_accuracy: 0.9831 - val_loss: 0.0519\n",
      "Epoch 461/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9902 - loss: 0.0389 - val_accuracy: 0.9785 - val_loss: 0.0638\n",
      "Epoch 462/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9878 - loss: 0.0371 - val_accuracy: 0.9808 - val_loss: 0.0554\n",
      "Epoch 463/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9838 - loss: 0.0496 - val_accuracy: 0.9808 - val_loss: 0.0568\n",
      "Epoch 464/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0397 - val_accuracy: 0.9854 - val_loss: 0.0562\n",
      "Epoch 465/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0427 - val_accuracy: 0.9785 - val_loss: 0.0642\n",
      "Epoch 466/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0439 - val_accuracy: 0.9831 - val_loss: 0.0541\n",
      "Epoch 467/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0395 - val_accuracy: 0.9823 - val_loss: 0.0532\n",
      "Epoch 468/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0366 - val_accuracy: 0.9815 - val_loss: 0.0538\n",
      "Epoch 469/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0386 - val_accuracy: 0.9838 - val_loss: 0.0532\n",
      "Epoch 470/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0371 - val_accuracy: 0.9792 - val_loss: 0.0538\n",
      "Epoch 471/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0359 - val_accuracy: 0.9823 - val_loss: 0.0514\n",
      "Epoch 472/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0409 - val_accuracy: 0.9838 - val_loss: 0.0529\n",
      "Epoch 473/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0399 - val_accuracy: 0.9823 - val_loss: 0.0518\n",
      "Epoch 474/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0408 - val_accuracy: 0.9792 - val_loss: 0.0546\n",
      "Epoch 475/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0383 - val_accuracy: 0.9815 - val_loss: 0.0552\n",
      "Epoch 476/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0378 - val_accuracy: 0.9808 - val_loss: 0.0522\n",
      "Epoch 477/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0389 - val_accuracy: 0.9823 - val_loss: 0.0511\n",
      "Epoch 478/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.0353 - val_accuracy: 0.9800 - val_loss: 0.0564\n",
      "Epoch 479/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0438 - val_accuracy: 0.9831 - val_loss: 0.0529\n",
      "Epoch 480/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0392 - val_accuracy: 0.9815 - val_loss: 0.0573\n",
      "Epoch 481/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0384 - val_accuracy: 0.9808 - val_loss: 0.0524\n",
      "Epoch 482/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0391 - val_accuracy: 0.9846 - val_loss: 0.0518\n",
      "Epoch 483/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0346 - val_accuracy: 0.9831 - val_loss: 0.0506\n",
      "Epoch 484/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0379 - val_accuracy: 0.9838 - val_loss: 0.0513\n",
      "Epoch 485/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0342 - val_accuracy: 0.9815 - val_loss: 0.0515\n",
      "Epoch 486/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0404 - val_accuracy: 0.9800 - val_loss: 0.0551\n",
      "Epoch 487/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0413 - val_accuracy: 0.9792 - val_loss: 0.0605\n",
      "Epoch 488/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0383 - val_accuracy: 0.9831 - val_loss: 0.0513\n",
      "Epoch 489/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0355 - val_accuracy: 0.9808 - val_loss: 0.0550\n",
      "Epoch 490/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0427 - val_accuracy: 0.9831 - val_loss: 0.0513\n",
      "Epoch 491/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0444 - val_accuracy: 0.9792 - val_loss: 0.0597\n",
      "Epoch 492/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0443 - val_accuracy: 0.9831 - val_loss: 0.0508\n",
      "Epoch 493/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0386 - val_accuracy: 0.9838 - val_loss: 0.0517\n",
      "Epoch 494/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0347 - val_accuracy: 0.9823 - val_loss: 0.0507\n",
      "Epoch 495/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0437 - val_accuracy: 0.9862 - val_loss: 0.0513\n",
      "Epoch 496/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0365 - val_accuracy: 0.9808 - val_loss: 0.0521\n",
      "Epoch 497/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0328 - val_accuracy: 0.9808 - val_loss: 0.0540\n",
      "Epoch 498/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0311 - val_accuracy: 0.9823 - val_loss: 0.0510\n",
      "Epoch 499/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.0367 - val_accuracy: 0.9831 - val_loss: 0.0510\n",
      "Epoch 500/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9911 - loss: 0.0315 - val_accuracy: 0.9808 - val_loss: 0.0513\n",
      "Epoch 501/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0413 - val_accuracy: 0.9831 - val_loss: 0.0535\n",
      "Epoch 502/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0420 - val_accuracy: 0.9854 - val_loss: 0.0521\n",
      "Epoch 503/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0359 - val_accuracy: 0.9831 - val_loss: 0.0509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9664 - val_loss: 0.0917 - val_accuracy: 0.9715\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9646 - val_loss: 0.0965 - val_accuracy: 0.9723\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.0916 - val_accuracy: 0.9731\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9659 - val_loss: 0.0908 - val_accuracy: 0.9723\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9648 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9666 - val_loss: 0.0926 - val_accuracy: 0.9738\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.0910 - val_accuracy: 0.9754\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9669 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9677 - val_loss: 0.0890 - val_accuracy: 0.9692\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9666 - val_loss: 0.0921 - val_accuracy: 0.9769\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9656 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9695 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9700 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.0881 - val_accuracy: 0.9754\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9700 - val_loss: 0.0873 - val_accuracy: 0.9754\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9672 - val_loss: 0.0919 - val_accuracy: 0.9769\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9705 - val_loss: 0.0861 - val_accuracy: 0.9746\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9705 - val_loss: 0.0857 - val_accuracy: 0.9738\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9702 - val_loss: 0.0855 - val_accuracy: 0.9738\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9710 - val_loss: 0.0854 - val_accuracy: 0.9769\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9702 - val_loss: 0.0850 - val_accuracy: 0.9777\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.0865 - val_accuracy: 0.9777\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9713 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9718 - val_loss: 0.0841 - val_accuracy: 0.9785\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9710 - val_loss: 0.0862 - val_accuracy: 0.9785\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9682 - val_loss: 0.0840 - val_accuracy: 0.9792\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9713 - val_loss: 0.0837 - val_accuracy: 0.9785\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 0.0827 - val_accuracy: 0.9762\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9707 - val_loss: 0.0829 - val_accuracy: 0.9785\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9710 - val_loss: 0.0834 - val_accuracy: 0.9785\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9720 - val_loss: 0.0849 - val_accuracy: 0.9777\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9713 - val_loss: 0.0855 - val_accuracy: 0.9769\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9713 - val_loss: 0.0817 - val_accuracy: 0.9754\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9728 - val_loss: 0.0816 - val_accuracy: 0.9754\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9702 - val_loss: 0.0882 - val_accuracy: 0.9769\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9723 - val_loss: 0.0803 - val_accuracy: 0.9777\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9687 - val_loss: 0.0916 - val_accuracy: 0.9746\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.0813 - val_accuracy: 0.9754\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9713 - val_loss: 0.0807 - val_accuracy: 0.9762\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9687 - val_loss: 0.0955 - val_accuracy: 0.9723\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.0799 - val_accuracy: 0.9792\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.0832 - val_accuracy: 0.9715\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9692 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 0.0804 - val_accuracy: 0.9792\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9718 - val_loss: 0.0833 - val_accuracy: 0.9715\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9707 - val_loss: 0.0805 - val_accuracy: 0.9785\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9705 - val_loss: 0.0848 - val_accuracy: 0.9762\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.0785 - val_accuracy: 0.9792\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9725 - val_loss: 0.0782 - val_accuracy: 0.9792\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.0805 - val_accuracy: 0.9792\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9723 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9738 - val_loss: 0.0777 - val_accuracy: 0.9785\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9733 - val_loss: 0.0789 - val_accuracy: 0.9800\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9715 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.0773 - val_accuracy: 0.9792\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9731 - val_loss: 0.0772 - val_accuracy: 0.9785\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9736 - val_loss: 0.0779 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9743 - val_loss: 0.0774 - val_accuracy: 0.9792\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9733 - val_loss: 0.0779 - val_accuracy: 0.9777\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0786 - val_accuracy: 0.9792\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 0.0811 - val_accuracy: 0.9777\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.0759 - val_accuracy: 0.9785\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9736 - val_loss: 0.0759 - val_accuracy: 0.9792\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.0763 - val_accuracy: 0.9800\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9741 - val_loss: 0.0765 - val_accuracy: 0.9800\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9736 - val_loss: 0.0755 - val_accuracy: 0.9792\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9738 - val_loss: 0.0754 - val_accuracy: 0.9777\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9741 - val_loss: 0.0752 - val_accuracy: 0.9792\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9749 - val_loss: 0.0773 - val_accuracy: 0.9792\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.0752 - val_accuracy: 0.9808\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9764 - val_loss: 0.0753 - val_accuracy: 0.9792\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9756 - val_loss: 0.0745 - val_accuracy: 0.9777\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9759 - val_loss: 0.0787 - val_accuracy: 0.9777\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.0749 - val_accuracy: 0.9777\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0738 - val_accuracy: 0.9808\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9759 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.0780 - val_accuracy: 0.9769\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.0756 - val_accuracy: 0.9792\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9741 - val_loss: 0.0817 - val_accuracy: 0.9769\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 0.0738 - val_accuracy: 0.9785\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9751 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9769 - val_loss: 0.0728 - val_accuracy: 0.9800\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0752 - val_accuracy: 0.9800\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.0742 - val_accuracy: 0.9785\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 0.0744 - val_accuracy: 0.9785\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9761 - val_loss: 0.0735 - val_accuracy: 0.9815\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9741 - val_loss: 0.0833 - val_accuracy: 0.9769\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9702 - val_loss: 0.0725 - val_accuracy: 0.9808\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.0722 - val_accuracy: 0.9808\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9766 - val_loss: 0.0724 - val_accuracy: 0.9808\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 0.0714 - val_accuracy: 0.9815\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.0716 - val_accuracy: 0.9800\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9782 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9777\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9761 - val_loss: 0.0763 - val_accuracy: 0.9769\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9736 - val_loss: 0.0711 - val_accuracy: 0.9800\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9761 - val_loss: 0.0726 - val_accuracy: 0.9800\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9784 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9751 - val_loss: 0.0716 - val_accuracy: 0.9808\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 0.0731 - val_accuracy: 0.9785\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9764 - val_loss: 0.0767 - val_accuracy: 0.9769\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 0.0704 - val_accuracy: 0.9792\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9769 - val_loss: 0.0709 - val_accuracy: 0.9800\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9772 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.0703 - val_accuracy: 0.9792\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9787 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9774 - val_loss: 0.0699 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9777 - val_loss: 0.0760 - val_accuracy: 0.9762\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.0866 - val_accuracy: 0.9746\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9710 - val_loss: 0.0723 - val_accuracy: 0.9808\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9777 - val_loss: 0.0687 - val_accuracy: 0.9800\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.0685 - val_accuracy: 0.9808\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9772 - val_loss: 0.0684 - val_accuracy: 0.9800\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0687 - val_accuracy: 0.9808\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9782 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.0677 - val_accuracy: 0.9815\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9790 - val_loss: 0.0681 - val_accuracy: 0.9800\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9784 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.0679 - val_accuracy: 0.9800\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 0.0675 - val_accuracy: 0.9831\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9795 - val_loss: 0.0672 - val_accuracy: 0.9831\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9782 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 0.0702 - val_accuracy: 0.9800\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9769 - val_loss: 0.0689 - val_accuracy: 0.9823\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9779 - val_loss: 0.0685 - val_accuracy: 0.9815\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0666 - val_accuracy: 0.9808\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.0683 - val_accuracy: 0.9808\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0672 - val_accuracy: 0.9815\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.0668 - val_accuracy: 0.9831\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9787 - val_loss: 0.0716 - val_accuracy: 0.9815\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.0691 - val_accuracy: 0.9831\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.0662 - val_accuracy: 0.9823\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9795 - val_loss: 0.0671 - val_accuracy: 0.9823\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0658 - val_accuracy: 0.9815\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9795 - val_loss: 0.0734 - val_accuracy: 0.9785\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9782 - val_loss: 0.0684 - val_accuracy: 0.9792\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9823\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0673 - val_accuracy: 0.9831\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.0667 - val_accuracy: 0.9800\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0653 - val_accuracy: 0.9808\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 0.0683 - val_accuracy: 0.9792\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.0665 - val_accuracy: 0.9823\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.0712 - val_accuracy: 0.9823\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 0.0662 - val_accuracy: 0.9823\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9800\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.0700 - val_accuracy: 0.9815\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.0658 - val_accuracy: 0.9823\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0668 - val_accuracy: 0.9800\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 0.0686 - val_accuracy: 0.9792\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.0684 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9823\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.0706 - val_accuracy: 0.9823\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.0660 - val_accuracy: 0.9808\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.0686 - val_accuracy: 0.9815\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.0649 - val_accuracy: 0.9823\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.0641 - val_accuracy: 0.9823\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9813 - val_loss: 0.0677 - val_accuracy: 0.9800\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9833 - val_loss: 0.0644 - val_accuracy: 0.9815\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9838\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.0646 - val_accuracy: 0.9823\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.0641 - val_accuracy: 0.9831\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9800\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9846\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.0654 - val_accuracy: 0.9838\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.0644 - val_accuracy: 0.9815\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9838\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.0651 - val_accuracy: 0.9831\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.0637 - val_accuracy: 0.9823\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9838\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0676 - val_accuracy: 0.9800\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9808\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9831\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0645 - val_accuracy: 0.9815\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.0649 - val_accuracy: 0.9808\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9818 - val_loss: 0.0647 - val_accuracy: 0.9815\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.0644 - val_accuracy: 0.9846\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0636 - val_accuracy: 0.9838\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9828 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 0.0636 - val_accuracy: 0.9838\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0674 - val_accuracy: 0.9831\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0649 - val_accuracy: 0.9815\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9808\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9831 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9823\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0641 - val_accuracy: 0.9831\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 0.0653 - val_accuracy: 0.9815\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0640 - val_accuracy: 0.9831\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 0.0673 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.0643 - val_accuracy: 0.9838\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 0.0633 - val_accuracy: 0.9854\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.0642 - val_accuracy: 0.9815\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9833 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 0.0634 - val_accuracy: 0.9831\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.0633 - val_accuracy: 0.9831\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0640 - val_accuracy: 0.9846\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.0634 - val_accuracy: 0.9838\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 0.0653 - val_accuracy: 0.9838\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9831\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 0.0654 - val_accuracy: 0.9831\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9831\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.0708 - val_accuracy: 0.9800\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9838 - val_loss: 0.0643 - val_accuracy: 0.9831\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 0.0641 - val_accuracy: 0.9854\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9813 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9838\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.0644 - val_accuracy: 0.9823\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.0628 - val_accuracy: 0.9854\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0640 - val_accuracy: 0.9831\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.0670 - val_accuracy: 0.9815\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0637 - val_accuracy: 0.9831\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.0664 - val_accuracy: 0.9831\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0631 - val_accuracy: 0.9838\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 0.0648 - val_accuracy: 0.9823\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0659 - val_accuracy: 0.9815\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9800\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9854\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9843 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.0656 - val_accuracy: 0.9823\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9828 - val_loss: 0.0651 - val_accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# 최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/Ch14-4-bestmodel.keras\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pP0Wcpbb_nG6",
    "outputId": "7a61f59d-30d3-4ec8-d080-479bf4cbb6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9803 - loss: 0.0918 \n",
      "Test accuracy: 0.9815384745597839\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ch14-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
