{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning_4th/blob/master/colab/ch14-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7461 - loss: 2.2717 - val_accuracy: 0.8023 - val_loss: 1.1409\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7981 - loss: 1.0185 - val_accuracy: 0.8677 - val_loss: 0.3178\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7727 - loss: 0.4411 - val_accuracy: 0.9062 - val_loss: 0.2605\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8845 - loss: 0.3208 - val_accuracy: 0.9154 - val_loss: 0.2675\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9044 - loss: 0.2756 - val_accuracy: 0.9138 - val_loss: 0.2436\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.2534 - val_accuracy: 0.9223 - val_loss: 0.2086\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9162 - loss: 0.2272 - val_accuracy: 0.9377 - val_loss: 0.1977\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9190 - loss: 0.2115 - val_accuracy: 0.9300 - val_loss: 0.2019\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9244 - loss: 0.2010 - val_accuracy: 0.9431 - val_loss: 0.1896\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9325 - loss: 0.1985 - val_accuracy: 0.9438 - val_loss: 0.1899\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9264 - loss: 0.2066 - val_accuracy: 0.9415 - val_loss: 0.1887\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.2019 - val_accuracy: 0.9454 - val_loss: 0.1841\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9291 - loss: 0.1999 - val_accuracy: 0.9415 - val_loss: 0.1853\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9242 - loss: 0.2095 - val_accuracy: 0.9454 - val_loss: 0.1797\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9302 - loss: 0.1971 - val_accuracy: 0.9469 - val_loss: 0.1814\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9335 - loss: 0.1895 - val_accuracy: 0.9454 - val_loss: 0.1765\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9298 - loss: 0.1892 - val_accuracy: 0.9469 - val_loss: 0.1764\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9324 - loss: 0.1919 - val_accuracy: 0.9462 - val_loss: 0.1757\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9357 - loss: 0.1873 - val_accuracy: 0.9469 - val_loss: 0.1725\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9330 - loss: 0.1877 - val_accuracy: 0.9485 - val_loss: 0.1723\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.1863 - val_accuracy: 0.9492 - val_loss: 0.1697\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9335 - loss: 0.1867 - val_accuracy: 0.9492 - val_loss: 0.1679\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9364 - loss: 0.1795 - val_accuracy: 0.9485 - val_loss: 0.1680\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9371 - loss: 0.1760 - val_accuracy: 0.9515 - val_loss: 0.1638\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9391 - loss: 0.1722 - val_accuracy: 0.9477 - val_loss: 0.1683\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9383 - loss: 0.1731 - val_accuracy: 0.9515 - val_loss: 0.1609\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9317 - loss: 0.1865 - val_accuracy: 0.9523 - val_loss: 0.1589\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9401 - loss: 0.1685 - val_accuracy: 0.9515 - val_loss: 0.1632\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9346 - loss: 0.1783 - val_accuracy: 0.9508 - val_loss: 0.1560\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.1787 - val_accuracy: 0.9477 - val_loss: 0.1579\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9368 - loss: 0.1663 - val_accuracy: 0.9523 - val_loss: 0.1545\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1677 - val_accuracy: 0.9523 - val_loss: 0.1528\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9377 - loss: 0.1672 - val_accuracy: 0.9523 - val_loss: 0.1509\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1513 - val_accuracy: 0.9531 - val_loss: 0.1585\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9422 - loss: 0.1609 - val_accuracy: 0.9523 - val_loss: 0.1472\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9385 - loss: 0.1664 - val_accuracy: 0.9523 - val_loss: 0.1460\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.1554 - val_accuracy: 0.9554 - val_loss: 0.1479\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9421 - loss: 0.1566 - val_accuracy: 0.9523 - val_loss: 0.1433\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9472 - loss: 0.1483 - val_accuracy: 0.9538 - val_loss: 0.1419\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9398 - loss: 0.1550 - val_accuracy: 0.9554 - val_loss: 0.1494\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.1502 - val_accuracy: 0.9554 - val_loss: 0.1409\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1555 - val_accuracy: 0.9546 - val_loss: 0.1390\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9440 - loss: 0.1488 - val_accuracy: 0.9538 - val_loss: 0.1407\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9459 - loss: 0.1490 - val_accuracy: 0.9546 - val_loss: 0.1470\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9466 - loss: 0.1495 - val_accuracy: 0.9569 - val_loss: 0.1347\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9440 - loss: 0.1510 - val_accuracy: 0.9562 - val_loss: 0.1340\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9474 - loss: 0.1396 - val_accuracy: 0.9562 - val_loss: 0.1426\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9483 - loss: 0.1410 - val_accuracy: 0.9554 - val_loss: 0.1364\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1353 - val_accuracy: 0.9569 - val_loss: 0.1309\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1376 - val_accuracy: 0.9577 - val_loss: 0.1290\n"
     ]
    }
   ],
   "source": [
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1372 \n",
      "Test accuracy: 0.9484615325927734\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 저장 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.2608.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.2608.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.9223.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.9215.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.9269.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.9315.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.9346.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.9323.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9362.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9354.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9346.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9362.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9354.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9377.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9362.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9377.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9369.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9392.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9385.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9392.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9392.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9392.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9392.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9385.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9400.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9400.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9400.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9423.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9431.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9423.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9431.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9400.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9446.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9431.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9462.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9454.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9462.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9469.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9477.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9500.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9508.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9508.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9492.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9508.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9508.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9515.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9538.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9500.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9508.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9500.keras\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다. \n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1470 \n",
      "Test accuracy: 0.939230740070343\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 확인을 위한 긴 학습 (컴퓨터 환경에 따라 시간이 다소 걸릴수 있습니다)\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954837</td>\n",
       "      <td>0.120094</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.119875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954580</td>\n",
       "      <td>0.117656</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.118537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.955350</td>\n",
       "      <td>0.116328</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.117845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959969</td>\n",
       "      <td>0.114956</td>\n",
       "      <td>0.949231</td>\n",
       "      <td>0.123824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.958173</td>\n",
       "      <td>0.115734</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.116390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.993328</td>\n",
       "      <td>0.024083</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.034690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.993585</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.036468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.028803</td>\n",
       "      <td>0.983846</td>\n",
       "      <td>0.050655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.035774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.987683</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.032132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.954837  0.120094      0.950769  0.119875\n",
       "1     0.954580  0.117656      0.953846  0.118537\n",
       "2     0.955350  0.116328      0.950769  0.117845\n",
       "3     0.959969  0.114956      0.949231  0.123824\n",
       "4     0.958173  0.115734      0.950000  0.116390\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.993328  0.024083      0.990769  0.034690\n",
       "1996  0.993585  0.022688      0.990769  0.036468\n",
       "1997  0.990249  0.028803      0.983846  0.050655\n",
       "1998  0.988196  0.033680      0.990000  0.035774\n",
       "1999  0.987683  0.036715      0.992308  0.032132\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다. \n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "# x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습의 자동 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7485 - loss: 3.3168 - val_accuracy: 0.7523 - val_loss: 2.4052\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7554 - loss: 2.1568 - val_accuracy: 0.7523 - val_loss: 1.4947\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7592 - loss: 1.3111 - val_accuracy: 0.7523 - val_loss: 0.8379\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7554 - loss: 0.6957 - val_accuracy: 0.7523 - val_loss: 0.3757\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7955 - loss: 0.3971 - val_accuracy: 0.8685 - val_loss: 0.3983\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8675 - loss: 0.3698 - val_accuracy: 0.8477 - val_loss: 0.3381\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8452 - loss: 0.3387 - val_accuracy: 0.8638 - val_loss: 0.3134\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8733 - loss: 0.3085 - val_accuracy: 0.8877 - val_loss: 0.2843\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.2846 - val_accuracy: 0.8977 - val_loss: 0.2675\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8992 - loss: 0.2666 - val_accuracy: 0.8977 - val_loss: 0.2536\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9053 - loss: 0.2525 - val_accuracy: 0.9062 - val_loss: 0.2429\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9130 - loss: 0.2430 - val_accuracy: 0.9123 - val_loss: 0.2345\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9128 - loss: 0.2367 - val_accuracy: 0.9146 - val_loss: 0.2268\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9158 - loss: 0.2326 - val_accuracy: 0.9215 - val_loss: 0.2196\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9168 - loss: 0.2238 - val_accuracy: 0.9277 - val_loss: 0.2131\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2220 - val_accuracy: 0.9323 - val_loss: 0.2072\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9285 - loss: 0.2015 - val_accuracy: 0.9331 - val_loss: 0.2018\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9307 - loss: 0.2044 - val_accuracy: 0.9354 - val_loss: 0.1975\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.1995 - val_accuracy: 0.9362 - val_loss: 0.1943\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.2009 - val_accuracy: 0.9362 - val_loss: 0.1921\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9374 - loss: 0.1958 - val_accuracy: 0.9369 - val_loss: 0.1907\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.2008 - val_accuracy: 0.9377 - val_loss: 0.1895\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.1885 - val_accuracy: 0.9385 - val_loss: 0.1882\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9370 - loss: 0.1899 - val_accuracy: 0.9377 - val_loss: 0.1868\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.1977 - val_accuracy: 0.9377 - val_loss: 0.1852\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9383 - loss: 0.1931 - val_accuracy: 0.9377 - val_loss: 0.1837\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9396 - loss: 0.1854 - val_accuracy: 0.9362 - val_loss: 0.1828\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9392 - loss: 0.1807 - val_accuracy: 0.9377 - val_loss: 0.1822\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9411 - loss: 0.1780 - val_accuracy: 0.9362 - val_loss: 0.1806\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9385 - loss: 0.1867 - val_accuracy: 0.9369 - val_loss: 0.1791\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9395 - loss: 0.1840 - val_accuracy: 0.9369 - val_loss: 0.1784\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9391 - loss: 0.1819 - val_accuracy: 0.9369 - val_loss: 0.1775\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9394 - loss: 0.1779 - val_accuracy: 0.9377 - val_loss: 0.1762\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9393 - loss: 0.1829 - val_accuracy: 0.9362 - val_loss: 0.1756\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9378 - loss: 0.1820 - val_accuracy: 0.9377 - val_loss: 0.1749\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9373 - loss: 0.1823 - val_accuracy: 0.9385 - val_loss: 0.1738\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9339 - loss: 0.1879 - val_accuracy: 0.9385 - val_loss: 0.1734\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9395 - loss: 0.1723 - val_accuracy: 0.9377 - val_loss: 0.1725\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9439 - loss: 0.1641 - val_accuracy: 0.9400 - val_loss: 0.1714\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9352 - loss: 0.1825 - val_accuracy: 0.9400 - val_loss: 0.1703\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9438 - loss: 0.1663 - val_accuracy: 0.9400 - val_loss: 0.1699\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9352 - loss: 0.1797 - val_accuracy: 0.9385 - val_loss: 0.1687\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9446 - loss: 0.1662 - val_accuracy: 0.9400 - val_loss: 0.1684\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9429 - loss: 0.1675 - val_accuracy: 0.9392 - val_loss: 0.1671\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9421 - loss: 0.1770 - val_accuracy: 0.9392 - val_loss: 0.1664\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9376 - loss: 0.1776 - val_accuracy: 0.9392 - val_loss: 0.1647\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9418 - loss: 0.1674 - val_accuracy: 0.9400 - val_loss: 0.1635\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9380 - loss: 0.1748 - val_accuracy: 0.9408 - val_loss: 0.1622\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9488 - loss: 0.1556 - val_accuracy: 0.9408 - val_loss: 0.1587\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9462 - loss: 0.1641 - val_accuracy: 0.9400 - val_loss: 0.1563\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9445 - loss: 0.1642 - val_accuracy: 0.9431 - val_loss: 0.1547\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9479 - loss: 0.1573 - val_accuracy: 0.9408 - val_loss: 0.1523\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9510 - loss: 0.1620 - val_accuracy: 0.9408 - val_loss: 0.1518\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9489 - loss: 0.1542 - val_accuracy: 0.9423 - val_loss: 0.1496\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9472 - loss: 0.1596 - val_accuracy: 0.9438 - val_loss: 0.1488\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9470 - loss: 0.1583 - val_accuracy: 0.9431 - val_loss: 0.1474\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.1629 - val_accuracy: 0.9400 - val_loss: 0.1504\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1420 - val_accuracy: 0.9454 - val_loss: 0.1514\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9501 - loss: 0.1498 - val_accuracy: 0.9377 - val_loss: 0.1556\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9508 - loss: 0.1381 - val_accuracy: 0.9454 - val_loss: 0.1481\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9487 - loss: 0.1461 - val_accuracy: 0.9423 - val_loss: 0.1435\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9547 - loss: 0.1360 - val_accuracy: 0.9446 - val_loss: 0.1418\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1443 - val_accuracy: 0.9423 - val_loss: 0.1415\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9510 - loss: 0.1408 - val_accuracy: 0.9446 - val_loss: 0.1397\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9497 - loss: 0.1416 - val_accuracy: 0.9423 - val_loss: 0.1396\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9493 - loss: 0.1414 - val_accuracy: 0.9469 - val_loss: 0.1377\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9511 - loss: 0.1365 - val_accuracy: 0.9469 - val_loss: 0.1355\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9523 - loss: 0.1294 - val_accuracy: 0.9485 - val_loss: 0.1342\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9540 - loss: 0.1342 - val_accuracy: 0.9462 - val_loss: 0.1340\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9535 - loss: 0.1284 - val_accuracy: 0.9477 - val_loss: 0.1324\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9551 - loss: 0.1206 - val_accuracy: 0.9485 - val_loss: 0.1308\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9517 - loss: 0.1366 - val_accuracy: 0.9477 - val_loss: 0.1308\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9516 - loss: 0.1312 - val_accuracy: 0.9492 - val_loss: 0.1296\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9589 - loss: 0.1256 - val_accuracy: 0.9477 - val_loss: 0.1312\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9532 - loss: 0.1273 - val_accuracy: 0.9508 - val_loss: 0.1272\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.1195 - val_accuracy: 0.9531 - val_loss: 0.1284\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9538 - loss: 0.1283 - val_accuracy: 0.9492 - val_loss: 0.1281\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9557 - loss: 0.1259 - val_accuracy: 0.9477 - val_loss: 0.1265\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9546 - loss: 0.1191 - val_accuracy: 0.9515 - val_loss: 0.1249\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.1094 - val_accuracy: 0.9546 - val_loss: 0.1248\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9542 - loss: 0.1225 - val_accuracy: 0.9523 - val_loss: 0.1232\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.1152 - val_accuracy: 0.9508 - val_loss: 0.1229\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9534 - loss: 0.1219 - val_accuracy: 0.9515 - val_loss: 0.1218\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9630 - loss: 0.1053 - val_accuracy: 0.9531 - val_loss: 0.1212\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9561 - loss: 0.1257 - val_accuracy: 0.9546 - val_loss: 0.1203\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.1178 - val_accuracy: 0.9492 - val_loss: 0.1260\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9515 - loss: 0.1274 - val_accuracy: 0.9585 - val_loss: 0.1205\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9612 - loss: 0.1153 - val_accuracy: 0.9592 - val_loss: 0.1192\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9616 - loss: 0.1189 - val_accuracy: 0.9515 - val_loss: 0.1222\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9530 - loss: 0.1272 - val_accuracy: 0.9508 - val_loss: 0.1234\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1108 - val_accuracy: 0.9662 - val_loss: 0.1223\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1129 - val_accuracy: 0.9538 - val_loss: 0.1165\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.1167 - val_accuracy: 0.9515 - val_loss: 0.1204\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.1139 - val_accuracy: 0.9623 - val_loss: 0.1160\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9591 - loss: 0.1105 - val_accuracy: 0.9562 - val_loss: 0.1144\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9634 - loss: 0.1077 - val_accuracy: 0.9538 - val_loss: 0.1154\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9580 - loss: 0.1128 - val_accuracy: 0.9569 - val_loss: 0.1134\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.1033 - val_accuracy: 0.9569 - val_loss: 0.1134\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9630 - loss: 0.1070 - val_accuracy: 0.9577 - val_loss: 0.1123\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9599 - loss: 0.1186 - val_accuracy: 0.9515 - val_loss: 0.1149\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9618 - loss: 0.1012 - val_accuracy: 0.9585 - val_loss: 0.1107\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9610 - loss: 0.1107 - val_accuracy: 0.9592 - val_loss: 0.1103\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9626 - loss: 0.1072 - val_accuracy: 0.9638 - val_loss: 0.1101\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9634 - loss: 0.1095 - val_accuracy: 0.9608 - val_loss: 0.1093\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9637 - loss: 0.1054 - val_accuracy: 0.9569 - val_loss: 0.1101\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9693 - loss: 0.0990 - val_accuracy: 0.9631 - val_loss: 0.1086\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9582 - loss: 0.1115 - val_accuracy: 0.9669 - val_loss: 0.1126\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9688 - loss: 0.1137 - val_accuracy: 0.9523 - val_loss: 0.1162\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.1133 - val_accuracy: 0.9562 - val_loss: 0.1093\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9616 - loss: 0.1063 - val_accuracy: 0.9654 - val_loss: 0.1068\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9661 - loss: 0.1023 - val_accuracy: 0.9654 - val_loss: 0.1060\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.1088 - val_accuracy: 0.9538 - val_loss: 0.1125\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.0993 - val_accuracy: 0.9654 - val_loss: 0.1042\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9622 - loss: 0.0967 - val_accuracy: 0.9685 - val_loss: 0.1072\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0980 - val_accuracy: 0.9600 - val_loss: 0.1044\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1109 - val_accuracy: 0.9569 - val_loss: 0.1095\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.1010 - val_accuracy: 0.9623 - val_loss: 0.1039\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: 0.1008 - val_accuracy: 0.9669 - val_loss: 0.1025\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9643 - loss: 0.1053 - val_accuracy: 0.9669 - val_loss: 0.1023\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0984 - val_accuracy: 0.9685 - val_loss: 0.1025\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9669 - loss: 0.0993 - val_accuracy: 0.9631 - val_loss: 0.1018\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0922 - val_accuracy: 0.9685 - val_loss: 0.1006\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0989 - val_accuracy: 0.9623 - val_loss: 0.1024\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9668 - loss: 0.0896 - val_accuracy: 0.9685 - val_loss: 0.1004\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9661 - loss: 0.0895 - val_accuracy: 0.9669 - val_loss: 0.0994\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0996 - val_accuracy: 0.9600 - val_loss: 0.1040\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 0.0983 - val_accuracy: 0.9677 - val_loss: 0.0988\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9662 - loss: 0.1009 - val_accuracy: 0.9654 - val_loss: 0.0986\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0944 - val_accuracy: 0.9646 - val_loss: 0.0986\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.0978 - val_accuracy: 0.9700 - val_loss: 0.0970\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0917 - val_accuracy: 0.9669 - val_loss: 0.0969\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9710 - loss: 0.0930 - val_accuracy: 0.9700 - val_loss: 0.0967\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9721 - loss: 0.0962 - val_accuracy: 0.9685 - val_loss: 0.0965\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9681 - loss: 0.0978 - val_accuracy: 0.9662 - val_loss: 0.0964\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0883 - val_accuracy: 0.9700 - val_loss: 0.0964\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9705 - loss: 0.0960 - val_accuracy: 0.9708 - val_loss: 0.0948\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.0885 - val_accuracy: 0.9708 - val_loss: 0.0942\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9726 - loss: 0.0939 - val_accuracy: 0.9669 - val_loss: 0.0961\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.0890 - val_accuracy: 0.9662 - val_loss: 0.0954\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9709 - loss: 0.0894 - val_accuracy: 0.9708 - val_loss: 0.0931\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.0938 - val_accuracy: 0.9692 - val_loss: 0.0930\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0882 - val_accuracy: 0.9646 - val_loss: 0.0959\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9683 - loss: 0.0970 - val_accuracy: 0.9708 - val_loss: 0.0918\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9723 - loss: 0.0939 - val_accuracy: 0.9715 - val_loss: 0.0916\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.0830 - val_accuracy: 0.9708 - val_loss: 0.0904\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0893 - val_accuracy: 0.9638 - val_loss: 0.0968\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9684 - loss: 0.0960 - val_accuracy: 0.9692 - val_loss: 0.0922\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9692 - loss: 0.0904 - val_accuracy: 0.9731 - val_loss: 0.0894\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9682 - loss: 0.0847 - val_accuracy: 0.9731 - val_loss: 0.0931\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9726 - loss: 0.0906 - val_accuracy: 0.9715 - val_loss: 0.0876\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0790 - val_accuracy: 0.9731 - val_loss: 0.0882\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.0861 - val_accuracy: 0.9715 - val_loss: 0.0890\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0924 - val_accuracy: 0.9715 - val_loss: 0.0867\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9724 - loss: 0.0798 - val_accuracy: 0.9731 - val_loss: 0.0861\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9787 - loss: 0.0828 - val_accuracy: 0.9723 - val_loss: 0.0852\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0758 - val_accuracy: 0.9731 - val_loss: 0.0846\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9796 - loss: 0.0726 - val_accuracy: 0.9731 - val_loss: 0.0842\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9783 - loss: 0.0767 - val_accuracy: 0.9723 - val_loss: 0.0842\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.0832 - val_accuracy: 0.9738 - val_loss: 0.0843\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0755 - val_accuracy: 0.9708 - val_loss: 0.0871\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.0988 - val_accuracy: 0.9692 - val_loss: 0.0912\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 0.0797 - val_accuracy: 0.9708 - val_loss: 0.0832\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0889 - val_accuracy: 0.9723 - val_loss: 0.0829\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0843 - val_accuracy: 0.9723 - val_loss: 0.0831\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0862 - val_accuracy: 0.9738 - val_loss: 0.0818\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0757 - val_accuracy: 0.9754 - val_loss: 0.0814\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0756 - val_accuracy: 0.9746 - val_loss: 0.0812\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0712 - val_accuracy: 0.9769 - val_loss: 0.0822\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0840 - val_accuracy: 0.9738 - val_loss: 0.0807\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9816 - loss: 0.0687 - val_accuracy: 0.9746 - val_loss: 0.0802\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0782 - val_accuracy: 0.9723 - val_loss: 0.0812\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.0734 - val_accuracy: 0.9769 - val_loss: 0.0814\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0772 - val_accuracy: 0.9754 - val_loss: 0.0790\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9798 - loss: 0.0719 - val_accuracy: 0.9746 - val_loss: 0.0790\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0769 - val_accuracy: 0.9754 - val_loss: 0.0789\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0700 - val_accuracy: 0.9754 - val_loss: 0.0792\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9785 - loss: 0.0746 - val_accuracy: 0.9746 - val_loss: 0.0780\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9805 - loss: 0.0750 - val_accuracy: 0.9762 - val_loss: 0.0779\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.0707 - val_accuracy: 0.9762 - val_loss: 0.0776\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0662 - val_accuracy: 0.9769 - val_loss: 0.0771\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0754 - val_accuracy: 0.9777 - val_loss: 0.0781\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0675 - val_accuracy: 0.9785 - val_loss: 0.0780\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9799 - loss: 0.0779 - val_accuracy: 0.9738 - val_loss: 0.0768\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0710 - val_accuracy: 0.9738 - val_loss: 0.0776\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0696 - val_accuracy: 0.9738 - val_loss: 0.0795\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9769 - loss: 0.0755 - val_accuracy: 0.9746 - val_loss: 0.0764\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9810 - loss: 0.0673 - val_accuracy: 0.9785 - val_loss: 0.0755\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0700 - val_accuracy: 0.9785 - val_loss: 0.0774\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0669 - val_accuracy: 0.9754 - val_loss: 0.0759\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0726 - val_accuracy: 0.9746 - val_loss: 0.0762\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0650 - val_accuracy: 0.9746 - val_loss: 0.0760\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0717 - val_accuracy: 0.9746 - val_loss: 0.0768\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9808 - loss: 0.0730 - val_accuracy: 0.9754 - val_loss: 0.0749\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9841 - loss: 0.0689 - val_accuracy: 0.9785 - val_loss: 0.0745\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9814 - loss: 0.0640 - val_accuracy: 0.9792 - val_loss: 0.0760\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9813 - loss: 0.0680 - val_accuracy: 0.9769 - val_loss: 0.0736\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0658 - val_accuracy: 0.9777 - val_loss: 0.0735\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0695 - val_accuracy: 0.9746 - val_loss: 0.0781\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.0646 - val_accuracy: 0.9746 - val_loss: 0.0743\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9796 - loss: 0.0719 - val_accuracy: 0.9762 - val_loss: 0.0802\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0733 - val_accuracy: 0.9746 - val_loss: 0.0731\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9810 - loss: 0.0648 - val_accuracy: 0.9762 - val_loss: 0.0724\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0626 - val_accuracy: 0.9800 - val_loss: 0.0723\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.0802 - val_accuracy: 0.9746 - val_loss: 0.0760\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9818 - loss: 0.0666 - val_accuracy: 0.9754 - val_loss: 0.0719\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0685 - val_accuracy: 0.9762 - val_loss: 0.0715\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0654 - val_accuracy: 0.9785 - val_loss: 0.0722\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0653 - val_accuracy: 0.9815 - val_loss: 0.0712\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0710 - val_accuracy: 0.9777 - val_loss: 0.0710\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9805 - loss: 0.0631 - val_accuracy: 0.9769 - val_loss: 0.0703\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0741 - val_accuracy: 0.9746 - val_loss: 0.0769\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0571 - val_accuracy: 0.9769 - val_loss: 0.0705\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.0614 - val_accuracy: 0.9792 - val_loss: 0.0697\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9803 - loss: 0.0731 - val_accuracy: 0.9792 - val_loss: 0.0704\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9816 - loss: 0.0657 - val_accuracy: 0.9762 - val_loss: 0.0713\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.0693 - val_accuracy: 0.9792 - val_loss: 0.0691\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0551 - val_accuracy: 0.9777 - val_loss: 0.0757\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0646 - val_accuracy: 0.9769 - val_loss: 0.0692\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0645 - val_accuracy: 0.9746 - val_loss: 0.0716\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.0663 - val_accuracy: 0.9762 - val_loss: 0.0710\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0596 - val_accuracy: 0.9823 - val_loss: 0.0698\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.0643 - val_accuracy: 0.9785 - val_loss: 0.0697\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9791 - loss: 0.0654 - val_accuracy: 0.9808 - val_loss: 0.0681\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9834 - loss: 0.0600 - val_accuracy: 0.9808 - val_loss: 0.0675\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0593 - val_accuracy: 0.9777 - val_loss: 0.0676\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9814 - loss: 0.0599 - val_accuracy: 0.9785 - val_loss: 0.0671\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0620 - val_accuracy: 0.9785 - val_loss: 0.0678\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9849 - loss: 0.0573 - val_accuracy: 0.9808 - val_loss: 0.0661\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.0556 - val_accuracy: 0.9808 - val_loss: 0.0663\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0611 - val_accuracy: 0.9754 - val_loss: 0.0707\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0699 - val_accuracy: 0.9754 - val_loss: 0.0706\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.0667 - val_accuracy: 0.9792 - val_loss: 0.0664\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0533 - val_accuracy: 0.9785 - val_loss: 0.0781\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9785 - loss: 0.0723 - val_accuracy: 0.9815 - val_loss: 0.0657\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9825 - loss: 0.0678 - val_accuracy: 0.9762 - val_loss: 0.0697\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0657 - val_accuracy: 0.9746 - val_loss: 0.0727\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9807 - loss: 0.0659 - val_accuracy: 0.9808 - val_loss: 0.0654\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9830 - loss: 0.0646 - val_accuracy: 0.9831 - val_loss: 0.0656\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9816 - loss: 0.0641 - val_accuracy: 0.9800 - val_loss: 0.0647\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0536 - val_accuracy: 0.9769 - val_loss: 0.0675\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9855 - loss: 0.0585 - val_accuracy: 0.9785 - val_loss: 0.0644\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0552 - val_accuracy: 0.9823 - val_loss: 0.0647\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0623 - val_accuracy: 0.9831 - val_loss: 0.0650\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0631 - val_accuracy: 0.9777 - val_loss: 0.0649\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0603 - val_accuracy: 0.9769 - val_loss: 0.0657\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0645 - val_accuracy: 0.9785 - val_loss: 0.0659\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0562 - val_accuracy: 0.9792 - val_loss: 0.0639\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.0598 - val_accuracy: 0.9800 - val_loss: 0.0629\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0574 - val_accuracy: 0.9831 - val_loss: 0.0635\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.0518 - val_accuracy: 0.9838 - val_loss: 0.0628\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9847 - loss: 0.0591 - val_accuracy: 0.9785 - val_loss: 0.0638\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0594 - val_accuracy: 0.9777 - val_loss: 0.0648\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0651 - val_accuracy: 0.9792 - val_loss: 0.0644\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9806 - loss: 0.0645 - val_accuracy: 0.9792 - val_loss: 0.0634\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0610 - val_accuracy: 0.9838 - val_loss: 0.0621\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0631 - val_accuracy: 0.9808 - val_loss: 0.0625\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0519 - val_accuracy: 0.9762 - val_loss: 0.0669\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0506 - val_accuracy: 0.9785 - val_loss: 0.0639\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0627 - val_accuracy: 0.9800 - val_loss: 0.0620\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0538 - val_accuracy: 0.9823 - val_loss: 0.0639\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0485 - val_accuracy: 0.9823 - val_loss: 0.0633\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.0625 - val_accuracy: 0.9808 - val_loss: 0.0619\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.0623 - val_accuracy: 0.9754 - val_loss: 0.0689\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0607 - val_accuracy: 0.9785 - val_loss: 0.0629\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0546 - val_accuracy: 0.9831 - val_loss: 0.0618\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0531 - val_accuracy: 0.9831 - val_loss: 0.0619\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9834 - loss: 0.0549 - val_accuracy: 0.9792 - val_loss: 0.0618\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0592 - val_accuracy: 0.9754 - val_loss: 0.0691\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0581 - val_accuracy: 0.9785 - val_loss: 0.0621\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9841 - loss: 0.0581 - val_accuracy: 0.9823 - val_loss: 0.0624\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0542 - val_accuracy: 0.9792 - val_loss: 0.0618\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9850 - loss: 0.0552 - val_accuracy: 0.9792 - val_loss: 0.0613\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9847 - loss: 0.0525 - val_accuracy: 0.9831 - val_loss: 0.0609\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0542 - val_accuracy: 0.9800 - val_loss: 0.0616\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9861 - loss: 0.0513 - val_accuracy: 0.9808 - val_loss: 0.0596\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0442 - val_accuracy: 0.9838 - val_loss: 0.0603\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0595 - val_accuracy: 0.9792 - val_loss: 0.0615\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0636 - val_accuracy: 0.9785 - val_loss: 0.0621\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0551 - val_accuracy: 0.9838 - val_loss: 0.0594\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0545 - val_accuracy: 0.9815 - val_loss: 0.0606\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0519 - val_accuracy: 0.9831 - val_loss: 0.0601\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0560 - val_accuracy: 0.9831 - val_loss: 0.0593\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0584 - val_accuracy: 0.9815 - val_loss: 0.0593\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0518 - val_accuracy: 0.9792 - val_loss: 0.0608\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0554 - val_accuracy: 0.9800 - val_loss: 0.0596\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.0485 - val_accuracy: 0.9831 - val_loss: 0.0610\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.0612 - val_accuracy: 0.9831 - val_loss: 0.0608\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0515 - val_accuracy: 0.9800 - val_loss: 0.0649\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0617 - val_accuracy: 0.9815 - val_loss: 0.0594\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0626 - val_accuracy: 0.9762 - val_loss: 0.0666\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0606 - val_accuracy: 0.9785 - val_loss: 0.0597\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0530 - val_accuracy: 0.9815 - val_loss: 0.0598\n",
      "Epoch 293/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0518 - val_accuracy: 0.9831 - val_loss: 0.0586\n",
      "Epoch 294/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0563 - val_accuracy: 0.9785 - val_loss: 0.0655\n",
      "Epoch 295/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9786 - loss: 0.0682 - val_accuracy: 0.9746 - val_loss: 0.0715\n",
      "Epoch 296/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0622 - val_accuracy: 0.9815 - val_loss: 0.0587\n",
      "Epoch 297/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0466 - val_accuracy: 0.9823 - val_loss: 0.0640\n",
      "Epoch 298/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0548 - val_accuracy: 0.9777 - val_loss: 0.0611\n",
      "Epoch 299/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0536 - val_accuracy: 0.9777 - val_loss: 0.0621\n",
      "Epoch 300/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0611 - val_accuracy: 0.9823 - val_loss: 0.0588\n",
      "Epoch 301/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.0519 - val_accuracy: 0.9823 - val_loss: 0.0613\n",
      "Epoch 302/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0610 - val_accuracy: 0.9815 - val_loss: 0.0594\n",
      "Epoch 303/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0550 - val_accuracy: 0.9831 - val_loss: 0.0585\n",
      "Epoch 304/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0516 - val_accuracy: 0.9846 - val_loss: 0.0579\n",
      "Epoch 305/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.0474 - val_accuracy: 0.9823 - val_loss: 0.0578\n",
      "Epoch 306/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0601 - val_accuracy: 0.9777 - val_loss: 0.0597\n",
      "Epoch 307/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0563 - val_accuracy: 0.9777 - val_loss: 0.0650\n",
      "Epoch 308/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0529 - val_accuracy: 0.9846 - val_loss: 0.0576\n",
      "Epoch 309/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0569 - val_accuracy: 0.9815 - val_loss: 0.0593\n",
      "Epoch 310/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0509 - val_accuracy: 0.9815 - val_loss: 0.0577\n",
      "Epoch 311/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0459 - val_accuracy: 0.9831 - val_loss: 0.0580\n",
      "Epoch 312/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0511 - val_accuracy: 0.9823 - val_loss: 0.0581\n",
      "Epoch 313/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0460 - val_accuracy: 0.9831 - val_loss: 0.0578\n",
      "Epoch 314/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0487 - val_accuracy: 0.9831 - val_loss: 0.0570\n",
      "Epoch 315/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0487 - val_accuracy: 0.9823 - val_loss: 0.0578\n",
      "Epoch 316/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0587 - val_accuracy: 0.9808 - val_loss: 0.0586\n",
      "Epoch 317/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0471 - val_accuracy: 0.9831 - val_loss: 0.0573\n",
      "Epoch 318/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0505 - val_accuracy: 0.9823 - val_loss: 0.0607\n",
      "Epoch 319/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0503 - val_accuracy: 0.9777 - val_loss: 0.0601\n",
      "Epoch 320/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0458 - val_accuracy: 0.9800 - val_loss: 0.0587\n",
      "Epoch 321/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9873 - loss: 0.0455 - val_accuracy: 0.9831 - val_loss: 0.0570\n",
      "Epoch 322/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0526 - val_accuracy: 0.9792 - val_loss: 0.0583\n",
      "Epoch 323/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0471 - val_accuracy: 0.9823 - val_loss: 0.0598\n",
      "Epoch 324/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0497 - val_accuracy: 0.9823 - val_loss: 0.0572\n",
      "Epoch 325/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0500 - val_accuracy: 0.9823 - val_loss: 0.0570\n",
      "Epoch 326/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0504 - val_accuracy: 0.9831 - val_loss: 0.0579\n",
      "Epoch 327/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0508 - val_accuracy: 0.9815 - val_loss: 0.0575\n",
      "Epoch 328/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0460 - val_accuracy: 0.9823 - val_loss: 0.0571\n",
      "Epoch 329/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0517 - val_accuracy: 0.9823 - val_loss: 0.0573\n",
      "Epoch 330/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0471 - val_accuracy: 0.9838 - val_loss: 0.0571\n",
      "Epoch 331/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9852 - loss: 0.0493 - val_accuracy: 0.9838 - val_loss: 0.0563\n",
      "Epoch 332/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0484 - val_accuracy: 0.9823 - val_loss: 0.0573\n",
      "Epoch 333/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0512 - val_accuracy: 0.9785 - val_loss: 0.0596\n",
      "Epoch 334/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0554 - val_accuracy: 0.9800 - val_loss: 0.0579\n",
      "Epoch 335/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0480 - val_accuracy: 0.9831 - val_loss: 0.0564\n",
      "Epoch 336/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0501 - val_accuracy: 0.9823 - val_loss: 0.0595\n",
      "Epoch 337/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0478 - val_accuracy: 0.9808 - val_loss: 0.0614\n",
      "Epoch 338/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0526 - val_accuracy: 0.9808 - val_loss: 0.0568\n",
      "Epoch 339/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0508 - val_accuracy: 0.9785 - val_loss: 0.0621\n",
      "Epoch 340/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0435 - val_accuracy: 0.9808 - val_loss: 0.0681\n",
      "Epoch 341/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0649 - val_accuracy: 0.9777 - val_loss: 0.0585\n",
      "Epoch 342/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0542 - val_accuracy: 0.9785 - val_loss: 0.0603\n",
      "Epoch 343/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0500 - val_accuracy: 0.9831 - val_loss: 0.0578\n",
      "Epoch 344/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0506 - val_accuracy: 0.9800 - val_loss: 0.0584\n",
      "Epoch 345/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0507 - val_accuracy: 0.9838 - val_loss: 0.0566\n",
      "Epoch 346/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0510 - val_accuracy: 0.9831 - val_loss: 0.0565\n",
      "Epoch 347/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0463 - val_accuracy: 0.9785 - val_loss: 0.0614\n",
      "Epoch 348/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0500 - val_accuracy: 0.9792 - val_loss: 0.0572\n",
      "Epoch 349/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 0.0483 - val_accuracy: 0.9823 - val_loss: 0.0578\n",
      "Epoch 350/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0484 - val_accuracy: 0.9815 - val_loss: 0.0588\n",
      "Epoch 351/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0455 - val_accuracy: 0.9823 - val_loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9664 - val_loss: 0.0917 - val_accuracy: 0.9715\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9646 - val_loss: 0.0965 - val_accuracy: 0.9723\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.0916 - val_accuracy: 0.9731\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9659 - val_loss: 0.0908 - val_accuracy: 0.9723\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9648 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9666 - val_loss: 0.0926 - val_accuracy: 0.9738\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.0910 - val_accuracy: 0.9754\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9669 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9677 - val_loss: 0.0890 - val_accuracy: 0.9692\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9666 - val_loss: 0.0921 - val_accuracy: 0.9769\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9656 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9695 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9700 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.0881 - val_accuracy: 0.9754\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9700 - val_loss: 0.0873 - val_accuracy: 0.9754\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9672 - val_loss: 0.0919 - val_accuracy: 0.9769\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9705 - val_loss: 0.0861 - val_accuracy: 0.9746\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9705 - val_loss: 0.0857 - val_accuracy: 0.9738\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9702 - val_loss: 0.0855 - val_accuracy: 0.9738\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9710 - val_loss: 0.0854 - val_accuracy: 0.9769\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9702 - val_loss: 0.0850 - val_accuracy: 0.9777\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.0865 - val_accuracy: 0.9777\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9713 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9718 - val_loss: 0.0841 - val_accuracy: 0.9785\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9710 - val_loss: 0.0862 - val_accuracy: 0.9785\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9682 - val_loss: 0.0840 - val_accuracy: 0.9792\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9713 - val_loss: 0.0837 - val_accuracy: 0.9785\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 0.0827 - val_accuracy: 0.9762\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9707 - val_loss: 0.0829 - val_accuracy: 0.9785\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9710 - val_loss: 0.0834 - val_accuracy: 0.9785\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9720 - val_loss: 0.0849 - val_accuracy: 0.9777\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9713 - val_loss: 0.0855 - val_accuracy: 0.9769\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9713 - val_loss: 0.0817 - val_accuracy: 0.9754\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9728 - val_loss: 0.0816 - val_accuracy: 0.9754\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9702 - val_loss: 0.0882 - val_accuracy: 0.9769\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9723 - val_loss: 0.0803 - val_accuracy: 0.9777\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9687 - val_loss: 0.0916 - val_accuracy: 0.9746\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.0813 - val_accuracy: 0.9754\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9713 - val_loss: 0.0807 - val_accuracy: 0.9762\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9687 - val_loss: 0.0955 - val_accuracy: 0.9723\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.0799 - val_accuracy: 0.9792\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.0832 - val_accuracy: 0.9715\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9692 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 0.0804 - val_accuracy: 0.9792\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9718 - val_loss: 0.0833 - val_accuracy: 0.9715\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9707 - val_loss: 0.0805 - val_accuracy: 0.9785\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9705 - val_loss: 0.0848 - val_accuracy: 0.9762\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.0785 - val_accuracy: 0.9792\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9725 - val_loss: 0.0782 - val_accuracy: 0.9792\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.0805 - val_accuracy: 0.9792\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9723 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9738 - val_loss: 0.0777 - val_accuracy: 0.9785\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9733 - val_loss: 0.0789 - val_accuracy: 0.9800\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9715 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.0773 - val_accuracy: 0.9792\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9731 - val_loss: 0.0772 - val_accuracy: 0.9785\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9736 - val_loss: 0.0779 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9743 - val_loss: 0.0774 - val_accuracy: 0.9792\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9733 - val_loss: 0.0779 - val_accuracy: 0.9777\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0786 - val_accuracy: 0.9792\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 0.0811 - val_accuracy: 0.9777\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.0759 - val_accuracy: 0.9785\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9736 - val_loss: 0.0759 - val_accuracy: 0.9792\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.0763 - val_accuracy: 0.9800\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9741 - val_loss: 0.0765 - val_accuracy: 0.9800\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9736 - val_loss: 0.0755 - val_accuracy: 0.9792\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9738 - val_loss: 0.0754 - val_accuracy: 0.9777\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9741 - val_loss: 0.0752 - val_accuracy: 0.9792\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9749 - val_loss: 0.0773 - val_accuracy: 0.9792\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.0752 - val_accuracy: 0.9808\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9764 - val_loss: 0.0753 - val_accuracy: 0.9792\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9756 - val_loss: 0.0745 - val_accuracy: 0.9777\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9759 - val_loss: 0.0787 - val_accuracy: 0.9777\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.0749 - val_accuracy: 0.9777\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0738 - val_accuracy: 0.9808\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9759 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.0780 - val_accuracy: 0.9769\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.0756 - val_accuracy: 0.9792\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9741 - val_loss: 0.0817 - val_accuracy: 0.9769\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 0.0738 - val_accuracy: 0.9785\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9751 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9769 - val_loss: 0.0728 - val_accuracy: 0.9800\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0752 - val_accuracy: 0.9800\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.0742 - val_accuracy: 0.9785\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 0.0744 - val_accuracy: 0.9785\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9761 - val_loss: 0.0735 - val_accuracy: 0.9815\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9741 - val_loss: 0.0833 - val_accuracy: 0.9769\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9702 - val_loss: 0.0725 - val_accuracy: 0.9808\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.0722 - val_accuracy: 0.9808\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9766 - val_loss: 0.0724 - val_accuracy: 0.9808\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 0.0714 - val_accuracy: 0.9815\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.0716 - val_accuracy: 0.9800\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9782 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9777\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9761 - val_loss: 0.0763 - val_accuracy: 0.9769\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9736 - val_loss: 0.0711 - val_accuracy: 0.9800\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9761 - val_loss: 0.0726 - val_accuracy: 0.9800\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9784 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9751 - val_loss: 0.0716 - val_accuracy: 0.9808\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 0.0731 - val_accuracy: 0.9785\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9764 - val_loss: 0.0767 - val_accuracy: 0.9769\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 0.0704 - val_accuracy: 0.9792\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9769 - val_loss: 0.0709 - val_accuracy: 0.9800\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9772 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.0703 - val_accuracy: 0.9792\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9787 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9774 - val_loss: 0.0699 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9777 - val_loss: 0.0760 - val_accuracy: 0.9762\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.0866 - val_accuracy: 0.9746\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9710 - val_loss: 0.0723 - val_accuracy: 0.9808\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9777 - val_loss: 0.0687 - val_accuracy: 0.9800\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.0685 - val_accuracy: 0.9808\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9772 - val_loss: 0.0684 - val_accuracy: 0.9800\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0687 - val_accuracy: 0.9808\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9782 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.0677 - val_accuracy: 0.9815\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9790 - val_loss: 0.0681 - val_accuracy: 0.9800\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9784 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.0679 - val_accuracy: 0.9800\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 0.0675 - val_accuracy: 0.9831\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9795 - val_loss: 0.0672 - val_accuracy: 0.9831\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9782 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 0.0702 - val_accuracy: 0.9800\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9769 - val_loss: 0.0689 - val_accuracy: 0.9823\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9779 - val_loss: 0.0685 - val_accuracy: 0.9815\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0666 - val_accuracy: 0.9808\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.0683 - val_accuracy: 0.9808\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0672 - val_accuracy: 0.9815\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.0668 - val_accuracy: 0.9831\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9787 - val_loss: 0.0716 - val_accuracy: 0.9815\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.0691 - val_accuracy: 0.9831\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.0662 - val_accuracy: 0.9823\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9795 - val_loss: 0.0671 - val_accuracy: 0.9823\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0658 - val_accuracy: 0.9815\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9795 - val_loss: 0.0734 - val_accuracy: 0.9785\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9782 - val_loss: 0.0684 - val_accuracy: 0.9792\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9823\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.0673 - val_accuracy: 0.9831\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.0667 - val_accuracy: 0.9800\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0653 - val_accuracy: 0.9808\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 0.0683 - val_accuracy: 0.9792\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.0665 - val_accuracy: 0.9823\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.0712 - val_accuracy: 0.9823\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 0.0662 - val_accuracy: 0.9823\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9800\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 0.0663 - val_accuracy: 0.9838\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.0700 - val_accuracy: 0.9815\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.0658 - val_accuracy: 0.9823\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0668 - val_accuracy: 0.9800\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 0.0686 - val_accuracy: 0.9792\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.0684 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9823\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.0706 - val_accuracy: 0.9823\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.0660 - val_accuracy: 0.9808\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.0686 - val_accuracy: 0.9815\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.0649 - val_accuracy: 0.9823\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.0641 - val_accuracy: 0.9823\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9813 - val_loss: 0.0677 - val_accuracy: 0.9800\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9833 - val_loss: 0.0644 - val_accuracy: 0.9815\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9838\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.0646 - val_accuracy: 0.9823\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.0641 - val_accuracy: 0.9831\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9800\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9846\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.0654 - val_accuracy: 0.9838\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.0644 - val_accuracy: 0.9815\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9838\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.0651 - val_accuracy: 0.9831\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.0637 - val_accuracy: 0.9823\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9838\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0676 - val_accuracy: 0.9800\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9808\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9831\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.0671 - val_accuracy: 0.9838\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0645 - val_accuracy: 0.9815\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.0649 - val_accuracy: 0.9808\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9818 - val_loss: 0.0647 - val_accuracy: 0.9815\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.0644 - val_accuracy: 0.9846\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0636 - val_accuracy: 0.9838\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9828 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 0.0636 - val_accuracy: 0.9838\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0674 - val_accuracy: 0.9831\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0649 - val_accuracy: 0.9815\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9808\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9831 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.0642 - val_accuracy: 0.9823\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0641 - val_accuracy: 0.9831\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 0.0653 - val_accuracy: 0.9815\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0640 - val_accuracy: 0.9831\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 0.0673 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.0643 - val_accuracy: 0.9838\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 0.0633 - val_accuracy: 0.9854\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.0642 - val_accuracy: 0.9815\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9833 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 0.0634 - val_accuracy: 0.9831\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.0633 - val_accuracy: 0.9831\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0640 - val_accuracy: 0.9846\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.0634 - val_accuracy: 0.9838\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 0.0653 - val_accuracy: 0.9838\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9831\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 0.0654 - val_accuracy: 0.9831\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9831\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.0708 - val_accuracy: 0.9800\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9838 - val_loss: 0.0643 - val_accuracy: 0.9831\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 0.0641 - val_accuracy: 0.9854\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9813 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9838\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.0644 - val_accuracy: 0.9823\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.0628 - val_accuracy: 0.9854\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0685 - val_accuracy: 0.9838\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0640 - val_accuracy: 0.9831\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.0670 - val_accuracy: 0.9815\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0637 - val_accuracy: 0.9831\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.0664 - val_accuracy: 0.9831\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0631 - val_accuracy: 0.9838\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 0.0648 - val_accuracy: 0.9823\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0659 - val_accuracy: 0.9815\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0653 - val_accuracy: 0.9823\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9800\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9854\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9843 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.0656 - val_accuracy: 0.9823\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9828 - val_loss: 0.0651 - val_accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단 될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "#최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/Ch14-4-bestmodel.keras\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "#모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0812 \n",
      "Test accuracy: 0.983846127986908\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
